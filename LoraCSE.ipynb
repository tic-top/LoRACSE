{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mD0FjgRWx5YR"
   },
   "source": [
    "# Download and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PUMNavxNeW6d",
    "outputId": "36de8a8c-69d1-43dc-8bf3-1e963b5e6af7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C4tMFlsPeoOO",
    "outputId": "398b7be2-977f-4f7e-b640-42c185abda1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/POCSE\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/POCSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/LoraCSE'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LISFxnwKeVYF"
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SKL6G0R8pqj4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/LoraCSE/data\n",
      "/home/LoraCSE/SentEval/data/downstream\n",
      "--2023-04-13 14:03:51--  https://huggingface.co/datasets/princeton-nlp/datasets-for-simcse/resolve/main/senteval.tar\n",
      "Resolving huggingface.co (huggingface.co)... 52.85.242.63, 52.85.242.6, 52.85.242.117, ...\n",
      "Connecting to huggingface.co (huggingface.co)|52.85.242.63|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs.huggingface.co/datasets/princeton-nlp/datasets-for-simcse/bc43c148f7be97471c78fc4255399d3158cb99dfe8f2221999c918338b138c38?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27senteval.tar%3B+filename%3D%22senteval.tar%22%3B&response-content-type=application%2Fx-tar&Expires=1681653831&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL2RhdGFzZXRzL3ByaW5jZXRvbi1ubHAvZGF0YXNldHMtZm9yLXNpbWNzZS9iYzQzYzE0OGY3YmU5NzQ3MWM3OGZjNDI1NTM5OWQzMTU4Y2I5OWRmZThmMjIyMTk5OWM5MTgzMzhiMTM4YzM4P3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiZyZXNwb25zZS1jb250ZW50LXR5cGU9KiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY4MTY1MzgzMX19fV19&Signature=GUjc7r-1cx15QYa7pYN64m4UO0U3hDQDlnb0NCFFzmdt6HswhL9hMW8cM4cXrDtUCPjjS0zu9pd7xq2dwFkQO8sR9Akt-SEiSfgnwrLHX0WcYtgWeBVExUwdiajIExxJIhNilZDMnOHZyu9WGXL5eIHywAeva0iK8QAu0mATveA9ox2PvtFNSOoCiEjVyTUPTxEmM-OV54f49NKiS%7EkTDArzoTZKPCUm%7EWt2Qiz%7Ers1pEyIZ3xnvD12HzMTG7zGfexjDm9gHUfdivM3ixCzTJ5RPjwD9JTUdxL2VPhpCAilRzwlyZL3F7gobw0PHhSUQ2ikELV37LBDlVE-Nb-s%7EwQ__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
      "--2023-04-13 14:03:51--  https://cdn-lfs.huggingface.co/datasets/princeton-nlp/datasets-for-simcse/bc43c148f7be97471c78fc4255399d3158cb99dfe8f2221999c918338b138c38?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27senteval.tar%3B+filename%3D%22senteval.tar%22%3B&response-content-type=application%2Fx-tar&Expires=1681653831&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL2RhdGFzZXRzL3ByaW5jZXRvbi1ubHAvZGF0YXNldHMtZm9yLXNpbWNzZS9iYzQzYzE0OGY3YmU5NzQ3MWM3OGZjNDI1NTM5OWQzMTU4Y2I5OWRmZThmMjIyMTk5OWM5MTgzMzhiMTM4YzM4P3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiZyZXNwb25zZS1jb250ZW50LXR5cGU9KiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY4MTY1MzgzMX19fV19&Signature=GUjc7r-1cx15QYa7pYN64m4UO0U3hDQDlnb0NCFFzmdt6HswhL9hMW8cM4cXrDtUCPjjS0zu9pd7xq2dwFkQO8sR9Akt-SEiSfgnwrLHX0WcYtgWeBVExUwdiajIExxJIhNilZDMnOHZyu9WGXL5eIHywAeva0iK8QAu0mATveA9ox2PvtFNSOoCiEjVyTUPTxEmM-OV54f49NKiS%7EkTDArzoTZKPCUm%7EWt2Qiz%7Ers1pEyIZ3xnvD12HzMTG7zGfexjDm9gHUfdivM3ixCzTJ5RPjwD9JTUdxL2VPhpCAilRzwlyZL3F7gobw0PHhSUQ2ikELV37LBDlVE-Nb-s%7EwQ__&Key-Pair-Id=KVTP0A1DKRTAX\n",
      "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 108.157.214.46, 108.157.214.82, 108.157.214.7, ...\n",
      "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|108.157.214.46|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 89825280 (86M) [application/x-tar]\n",
      "Saving to: ‘senteval.tar’\n",
      "\n",
      "senteval.tar        100%[===================>]  85.66M  32.5MB/s    in 2.6s    \n",
      "\n",
      "2023-04-13 14:03:54 (32.5 MB/s) - ‘senteval.tar’ saved [89825280/89825280]\n",
      "\n",
      "CR/\n",
      "CR/custrev.neg\n",
      "CR/custrev.pos\n",
      "MPQA/\n",
      "MPQA/mpqa.neg\n",
      "MPQA/mpqa.pos\n",
      "MR/\n",
      "MR/rt-polarity.neg\n",
      "MR/rt-polarity.pos\n",
      "MRPC/\n",
      "MRPC/msr_paraphrase_train.txt\n",
      "MRPC/msr_paraphrase_test.txt\n",
      "SICK/\n",
      "SICK/SICK_trial.txt\n",
      "SICK/SICK_train.txt\n",
      "SICK/SICK_test_annotated.txt\n",
      "SNLI/\n",
      "SNLI/s2.test\n",
      "SNLI/s1.train\n",
      "SNLI/s2.train\n",
      "SNLI/labels.dev\n",
      "SNLI/s1.test\n",
      "SNLI/labels.test\n",
      "SNLI/s2.dev\n",
      "SNLI/s1.dev\n",
      "SNLI/labels.train\n",
      "SST/\n",
      "SST/fine/\n",
      "SST/fine/sentiment-test\n",
      "SST/fine/sentiment-train\n",
      "SST/fine/sentiment-dev\n",
      "SST/binary/\n",
      "SST/binary/sentiment-test\n",
      "SST/binary/sentiment-train\n",
      "SST/binary/sentiment-dev\n",
      "STS/\n",
      "STS/STS12-en-test/\n",
      "STS/STS12-en-test/STS.gs.surprise.OnWN.txt\n",
      "STS/STS12-en-test/STS.input.surprise.OnWN.txt\n",
      "STS/STS12-en-test/STS.input.MSRpar.txt\n",
      "STS/STS12-en-test/STS.gs.ALL.txt\n",
      "STS/STS12-en-test/00-readme.txt\n",
      "STS/STS12-en-test/STS.gs.MSRvid.txt\n",
      "STS/STS12-en-test/STS.input.MSRvid.txt\n",
      "STS/STS12-en-test/STS.gs.MSRpar.txt\n",
      "STS/STS12-en-test/STS.input.surprise.SMTnews.txt\n",
      "STS/STS12-en-test/STS.gs.SMTeuroparl.txt\n",
      "STS/STS12-en-test/STS.gs.surprise.SMTnews.txt\n",
      "STS/STS12-en-test/STS.input.SMTeuroparl.txt\n",
      "STS/STS14-en-test/\n",
      "STS/STS14-en-test/STS.input.headlines.txt\n",
      "STS/STS14-en-test/STS.gs.OnWN.txt\n",
      "STS/STS14-en-test/STS.gs.images.txt\n",
      "STS/STS14-en-test/STS.gs.deft-news.txt\n",
      "STS/STS14-en-test/STS.gs.tweet-news.txt\n",
      "STS/STS14-en-test/sts2012-train.tgz\n",
      "STS/STS14-en-test/sts2013-test.tgz\n",
      "STS/STS14-en-test/00-readme.txt\n",
      "STS/STS14-en-test/STS.input.OnWN.txt\n",
      "STS/STS14-en-test/STS.input.deft-news.txt\n",
      "STS/STS14-en-test/sts2012-test.tgz\n",
      "STS/STS14-en-test/STS.input.deft-forum.txt\n",
      "STS/STS14-en-test/STS.output.headlines.txt\n",
      "STS/STS14-en-test/correlation-noconfidence.pl\n",
      "STS/STS14-en-test/STS.gs.headlines.txt\n",
      "STS/STS14-en-test/STS.gs.deft-forum.txt\n",
      "STS/STS14-en-test/STS.input.tweet-news.txt\n",
      "STS/STS14-en-test/STS.input.images.txt\n",
      "STS/STS15-en-test/\n",
      "STS/STS15-en-test/STS.input.headlines.txt\n",
      "STS/STS15-en-test/STS.gs.images.txt\n",
      "STS/STS15-en-test/STS.gs.answers-students.txt\n",
      "STS/STS15-en-test/00-readme.txt\n",
      "STS/STS15-en-test/STS.input.answers-students.txt\n",
      "STS/STS15-en-test/STS.input.answers-forums.LICENSE\n",
      "STS/STS15-en-test/STS.gs.answers-forums.txt\n",
      "STS/STS15-en-test/STS.input.answers-forums.txt\n",
      "STS/STS15-en-test/STS.gs.belief.txt\n",
      "STS/STS15-en-test/correlation-noconfidence.pl\n",
      "STS/STS15-en-test/STS.input.belief.txt\n",
      "STS/STS15-en-test/STS.gs.headlines.txt\n",
      "STS/STS15-en-test/STS.answers-forums.zip\n",
      "STS/STS15-en-test/corebaseline-tokencos.tar.gz\n",
      "STS/STS15-en-test/STS.input.images.txt\n",
      "STS/STS13-en-test/\n",
      "STS/STS13-en-test/STS.input.headlines.txt\n",
      "STS/STS13-en-test/STS.gs.OnWN.txt\n",
      "STS/STS13-en-test/correlation.pl\n",
      "STS/STS13-en-test/STS.input.FNWN.txt\n",
      "STS/STS13-en-test/STS.gs.FNWN.txt\n",
      "STS/STS13-en-test/STS.output.FNWN.txt\n",
      "STS/STS13-en-test/00-readme.txt\n",
      "STS/STS13-en-test/correlation-all.pl\n",
      "STS/STS13-en-test/STS.input.OnWN.txt\n",
      "STS/STS13-en-test/STS.output.headlines.txt\n",
      "STS/STS13-en-test/correct-output.pl\n",
      "STS/STS13-en-test/STS.gs.headlines.txt\n",
      "STS/STS13-en-test/STS.output.SMT.txt\n",
      "STS/STS13-en-test/STS.gs.SMT.txt\n",
      "STS/STS13-en-test/STS.output.OnWN.txt\n",
      "STS/STSBenchmark/\n",
      "STS/STSBenchmark/correlation.pl\n",
      "STS/STSBenchmark/sts-test.csv\n",
      "STS/STSBenchmark/readme.txt\n",
      "STS/STSBenchmark/LICENSE.txt\n",
      "STS/STSBenchmark/sts-train.csv\n",
      "STS/STSBenchmark/sts-dev.csv\n",
      "STS/STS16-en-test/\n",
      "STS/STS16-en-test/STS.input.headlines.txt\n",
      "STS/STS16-en-test/STS.gs.plagiarism.txt\n",
      "STS/STS16-en-test/STS.gs.question-question.txt\n",
      "STS/STS16-en-test/STS.input.question-question.txt\n",
      "STS/STS16-en-test/STS2016.input.headlines.ascii\n",
      "STS/STS16-en-test/README.txt\n",
      "STS/STS16-en-test/STS.gs.answer-answer.txt\n",
      "STS/STS16-en-test/STS2016.input.question-question.ascii\n",
      "STS/STS16-en-test/STS.input.postediting.txt\n",
      "STS/STS16-en-test/STS.input.plagiarism.txt\n",
      "STS/STS16-en-test/STS.gs.postediting.txt\n",
      "STS/STS16-en-test/LICENSE.txt\n",
      "STS/STS16-en-test/STS.input.answer-answer.txt\n",
      "STS/STS16-en-test/correlation-noconfidence.pl\n",
      "STS/STS16-en-test/STS.gs.headlines.txt\n",
      "STS/STS16-en-test/STS2016.input.answer-answer.ascii\n",
      "STS/STS16-en-test/STS2016.input.postediting.ascii\n",
      "STS/STS16-en-test/STS2016.input.plagiarism.ascii\n",
      "SUBJ/\n",
      "SUBJ/subj.subjective\n",
      "SUBJ/subj.objective\n",
      "TREC/\n",
      "TREC/train_5500.label\n",
      "TREC/TREC_10.label\n"
     ]
    }
   ],
   "source": [
    "%cd data\n",
    "!bash download_wiki.sh\n",
    "!bash download_nli.sh\n",
    "%cd ../SentEval/data/downstream\n",
    "!bash download_dataset.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "447aJ1GDeVYH"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from typing import Dict, List\n",
    "from lion_pytorch import Lion\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from loguru import logger\n",
    "from scipy.stats import spearmanr\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    BertConfig,\n",
    "    BertModel, \n",
    "    BertTokenizer,\n",
    "    DistilBertTokenizer, \n",
    "    DistilBertModel, \n",
    "    DistilBertConfig,\n",
    "    default_data_collator,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_config,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    set_peft_model_state_dict,\n",
    "    LoraConfig,\n",
    "    PeftType,\n",
    "    PrefixTuningConfig,\n",
    "    PromptEncoderConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8K8lwbn2NoW"
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OEqJVBZ9eVYI"
   },
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "EPOCHS = 4\n",
    "BATCH_SIZE = 512\n",
    "LR = 2e-4\n",
    "DROPOUT = 0.05\n",
    "MAXLEN = 32\n",
    "POOLING = 'cls'   # choose in ['cls', 'pooler', 'first-last-avg', 'last-avg']\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "RAND_SIZE = 0\n",
    "RAND_STD = 0.5\n",
    "RANK = 2\n",
    "SAVE_FREQ = 100\n",
    "PEFT_CONFIG = LoraConfig(inference_mode=False, \n",
    "              r=RANK, \n",
    "              lora_alpha=RANK*2, \n",
    "              lora_dropout=0.05,\n",
    "              # target_modules=[\"q_lin\",\"k_lin\"]\n",
    "              target_modules=['value','query']\n",
    "              )\n",
    "HID = 768\n",
    "# PEFT_CONFIG = PrefixTuningConfig(task_type=\"SEQ_CLS\",num_virtual_tokens=20)\n",
    "\n",
    "# Pretrain model\n",
    "DISBERT = 'distilbert-base-uncased'\n",
    "ROBERTA = 'roberta-base'\n",
    "ROBERTA_LARGE = 'roberta-large'\n",
    "BERT = 'bert-base-uncased'\n",
    "T5 = \"t5-small\"\n",
    "model_path = ROBERTA_LARGE\n",
    "\n",
    "# where to save\n",
    "# SAVE_PATH = './saved_model/simcse_unsup_qv_roberta_large.pt'\n",
    "SAVE_PATH = f'./saved_model/loracse_sup_{model_path}_r{RANK}_b{BATCH_SIZE}.pt'\n",
    "\n",
    "# dataset dir\n",
    "# DATA_PATH = './data/wiki1m_for_simcse.txt'\n",
    "DATA_PATH = './data/nli_for_simcse.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izHRSyiNyHn8"
   },
   "source": [
    "# Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/LoraCSE\n"
     ]
    }
   ],
   "source": [
    "%cd ../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZalkGIJueVYI",
    "outputId": "305f316b-a645-46df-99e3-ce0c92487484"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset csv (./data/csv/default-70806cc3f53ac92e/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "data_files = {}\n",
    "data_files['train'] = DATA_PATH\n",
    "extension = DATA_PATH.split(\".\")[-1]\n",
    "if extension == \"txt\":\n",
    "    extension = \"text\"\n",
    "if extension == \"csv\":\n",
    "    datasets = load_dataset(extension, data_files=data_files, cache_dir=\"./data/\", delimiter=\"\\t\" if \"tsv\" in DATA_PATH else \",\")\n",
    "else:\n",
    "    datasets = load_dataset(extension, data_files=data_files, cache_dir=\"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zLYi7QpIfoBs"
   },
   "outputs": [],
   "source": [
    "column_names = datasets[\"train\"].column_names\n",
    "sent2_cname = None\n",
    "if len(column_names) == 2:\n",
    "    # Pair datasets\n",
    "    sent0_cname = column_names[0]\n",
    "    sent1_cname = column_names[1]\n",
    "elif len(column_names) == 3:\n",
    "    # Pair datasets with hard negatives\n",
    "    sent0_cname = column_names[0]\n",
    "    sent1_cname = column_names[1]\n",
    "    sent2_cname = column_names[2]\n",
    "elif len(column_names) == 1:\n",
    "    # Unsupervised datasets\n",
    "    sent0_cname = column_names[0]\n",
    "    sent1_cname = column_names[0]\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Msm0O_KIfj2V",
    "outputId": "ef6c6e80-6ae5-43e9-8dd7-0d759535f81f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def prepare_features(examples):\n",
    "        # padding = longest (default)\n",
    "        #   If no sentence in the batch exceed the max length, then use\n",
    "        #   the max sentence length in the batch, otherwise use the \n",
    "        #   max sentence length in the argument and truncate those that\n",
    "        #   exceed the max length.\n",
    "        # padding = max_length (when pad_to_max_length, for pressure test)\n",
    "        #   All sentences are padded/truncated to data_args.max_seq_length.\n",
    "        total = len(examples[sent0_cname])\n",
    "\n",
    "        # Avoid \"None\" fields \n",
    "        for idx in range(total):\n",
    "            if examples[sent0_cname][idx] is None:\n",
    "                examples[sent0_cname][idx] = \" \"\n",
    "            if examples[sent1_cname][idx] is None:\n",
    "                examples[sent1_cname][idx] = \" \"\n",
    "        \n",
    "        sentences = examples[sent0_cname] + examples[sent1_cname]\n",
    "\n",
    "        # If hard negative exists\n",
    "        if sent2_cname is not None:\n",
    "            for idx in range(total):\n",
    "                if examples[sent2_cname][idx] is None:\n",
    "                    examples[sent2_cname][idx] = \" \"\n",
    "            sentences += examples[sent2_cname]\n",
    "\n",
    "        sent_features = tokenizer(\n",
    "            sentences,\n",
    "            max_length=32, #data_args.max_seq_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\" #if data_args.pad_to_max_length else False,\n",
    "        )\n",
    "\n",
    "        features = {}\n",
    "        if sent2_cname is not None:\n",
    "            for key in sent_features:\n",
    "                features[key] = [[sent_features[key][i], sent_features[key][i+total], sent_features[key][i+total*2]] for i in range(total)]\n",
    "        else:\n",
    "            for key in sent_features:\n",
    "                features[key] = [[sent_features[key][i], sent_features[key][i+total]] for i in range(total)]\n",
    "        return features\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "train_dataset = datasets[\"train\"].map(\n",
    "        prepare_features,\n",
    "        batched=True,\n",
    "        num_proc=32,\n",
    "        remove_columns=column_names,\n",
    "        load_from_cache_file=False,\n",
    "    )\n",
    "data_collator = default_data_collator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAu_bxbcyRMs"
   },
   "source": [
    "# Lora-CSE model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5EXlNRc1sJP"
   },
   "source": [
    "## model and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "sPuhlxx0eVYJ"
   },
   "outputs": [],
   "source": [
    "class MLPLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Head for getting sentence representations over RoBERTa/BERT's CLS representation.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "    def forward(self, features, **kwargs):\n",
    "        x = self.dense(features)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "    \n",
    "class SimcseModel(nn.Module):\n",
    "    \"\"\"Simcse\"\"\"\n",
    "    def __init__(self, pretrained_model, pooling, peft_config):\n",
    "        super(SimcseModel, self).__init__()\n",
    "        config = AutoConfig.from_pretrained(pretrained_model, return_dict=True)       \n",
    "        config.attention_probs_dropout_prob = DROPOUT   # 修改config的dropout系数\n",
    "        config.hidden_dropout_prob = DROPOUT           \n",
    "        self.bert = AutoModel.from_pretrained(pretrained_model)\n",
    "        self.pooling = pooling\n",
    "        self.bert = get_peft_model(self.bert, peft_config)\n",
    "        self.bert.print_trainable_parameters()\n",
    "        self.cls = MLPLayer(config)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None, test=False):\n",
    "        batch_size = input_ids.size(0)\n",
    "        if (len(input_ids.shape))==3:\n",
    "          #num_sent = 2 pair, 3 supervised\n",
    "          num_sent = input_ids.size(1)\n",
    "          mlm_outputs = None\n",
    "          # Flatten input for encoding\n",
    "          input_ids = input_ids.view((-1, input_ids.size(-1))) # (bs * num_sent, len)\n",
    "          attention_mask = attention_mask.view((-1, attention_mask.size(-1))) # (bs * num_sent len)\n",
    "          if token_type_ids is not None:\n",
    "              token_type_ids = token_type_ids.view((-1, token_type_ids.size(-1))) # (bs * num_sent, len)\n",
    "        else:\n",
    "          num_sent = 1\n",
    "        x = self.bert(input_ids, attention_mask, token_type_ids, output_hidden_states=True)\n",
    "\n",
    "        if self.pooling == 'cls':\n",
    "            x = x.last_hidden_state[:, 0]\n",
    "            x = x.view((batch_size, num_sent, -1))\n",
    "            return self.cls(x)    # [batch, num_sent, 768]          \n",
    "        \n",
    "        if self.pooling == 'pooler':\n",
    "            x = x.pooler_output   # [batch * num_sent, 768]\n",
    "            return x.view((batch_size, num_sent, -1))     # [batch, num_sent, 768]            \n",
    "        \n",
    "        if self.pooling == 'last-avg':\n",
    "            last = x.last_hidden_state.transpose(1, 2)    # [batch * num_sent, 768, seqlen]\n",
    "            x = torch.avg_pool1d(last, kernel_size=last.shape[-1]).squeeze(-1)       # [batch * num_sent, 768]\n",
    "            return x.view((batch_size, num_sent, -1))     # [batch, num_sent, 768]     \n",
    "\n",
    "        if self.pooling == 'first-last-avg':\n",
    "            first = x.hidden_states[1].transpose(1, 2)    # [batch * num_sent, 768, seqlen]\n",
    "            last = x.hidden_states[-1].transpose(1, 2)    # [batch * num_sent, 768, seqlen]                   \n",
    "            first_avg = torch.avg_pool1d(first, kernel_size=last.shape[-1]).squeeze(-1) # [batch * num_sent, 768]\n",
    "            last_avg = torch.avg_pool1d(last, kernel_size=last.shape[-1]).squeeze(-1)   # [batch * num_sent, 768]\n",
    "            avg = torch.cat((first_avg.unsqueeze(1), last_avg.unsqueeze(1)), dim=1)     # [batch * num_sent, 2, 768]\n",
    "            x = torch.avg_pool1d(avg.transpose(1, 2), kernel_size=2).squeeze(-1)     # [batch * num_sent, 768]\n",
    "            return x.view((batch_size, num_sent, -1))     # [batch, num_sent, 768]  \n",
    "\n",
    "def simcse_unsup_loss(y_pred: 'tensor') -> 'tensor':\n",
    "    \"\"\"Infocse loss\n",
    "    y_pred (tensor): the output of SIMCSE, [batch_size, num_sent, 768]\n",
    "    \n",
    "    \"\"\"\n",
    "    # get the batch size and number of sentences\n",
    "    batch_size = y_pred.size(0)\n",
    "    num_sent = y_pred.size(1)\n",
    "\n",
    "    # output\n",
    "    z1 = y_pred[:, 0]   # [batch_size, 768]\n",
    "    z2 = y_pred[:, 1]   # [batch_size, 768]\n",
    "    if num_sent >= 3:\n",
    "        z3 = y_pred[:, 2]   # [batch_size, 768]\n",
    "    #similarity\n",
    "    cos_sim = F.cosine_similarity(z1.unsqueeze(1), z2.unsqueeze(0), dim=-1) # [batch_size, batch_size]\n",
    "    if num_sent >= 3:\n",
    "        z1_z3_cos = F.cosine_similarity(z1.unsqueeze(1), z3.unsqueeze(0), dim=-1) # [batch_size, batch_size]\n",
    "        cos_sim = torch.cat([cos_sim, z1_z3_cos], 1) # [batch_size, 2 * batch_size]\n",
    "\n",
    "    #gsinfonce\n",
    "    if RAND_SIZE > 0:\n",
    "        #import ipdb;ipdb.set_trace()\n",
    "        if RAND_STD == 0.0 :\n",
    "            z2_random = torch.randn(RAND_STD, z1.shape[1]).to(DEVICE)\n",
    "        else:\n",
    "            z2_random = torch.normal(0, RAND_STD, size=(RAND_SIZE, z1.shape[1])).to(DEVICE)\n",
    "        cos_sim = torch.cat((cos_sim, F.cosine_similarity(z1.unsqueeze(1), z2_random.unsqueeze(0))),1).to(DEVICE)\n",
    "\n",
    "    \n",
    "    labels = torch.arange(cos_sim.size(0)).long().to(DEVICE) # [batch_size]\n",
    "    cos_sim /= 0.05\n",
    "    loss_fct = nn.CrossEntropyLoss()\n",
    "    loss = loss_fct(cos_sim, labels) #[batch_size]\n",
    "    return loss\n",
    "\n",
    "def mlm_loss(y_pred: 'tensor') -> 'tensor':\n",
    "    \"\"\"mlm loss\n",
    "    y_pred (tensor): the output of SIMCSE, [batch_size, num_sent, 768]\n",
    "    \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "af6MdT8N1iSu"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gXpbVc3b2EBP"
   },
   "outputs": [],
   "source": [
    "# Set path to SentEval\n",
    "PATH_TO_SENTEVAL = './SentEval'\n",
    "PATH_TO_DATA = './SentEval/data'\n",
    "\n",
    "# Import SentEval\n",
    "sys.path.insert(0, PATH_TO_SENTEVAL)\n",
    "import senteval\n",
    "def evaluate(eval_senteval_transfer: bool, tokenizer, model) -> Dict[str, float]:\n",
    "    # SentEval prepare and batcher\n",
    "    def prepare(params, samples):\n",
    "        return\n",
    "\n",
    "    def batcher(params, batch):\n",
    "        sentences = [' '.join(s) for s in batch]\n",
    "        batch = tokenizer.batch_encode_plus(\n",
    "            sentences,\n",
    "            return_tensors='pt',\n",
    "            padding=True,\n",
    "        )\n",
    "        for k in batch:\n",
    "            batch[k] = batch[k].to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            pooler_output = model(**batch, test=True).view((-1,HID))\n",
    "        return pooler_output.cpu()\n",
    "\n",
    "    # Set params for SentEval (fastmode)\n",
    "    params = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 5}\n",
    "    params['classifier'] = {'nhid': 0, 'optim': 'rmsprop', 'batch_size': 128,\n",
    "                                        'tenacity': 3, 'epoch_size': 2}\n",
    "\n",
    "    se = senteval.engine.SE(params, batcher, prepare)\n",
    "    tasks = ['STSBenchmark', 'SICKRelatedness']\n",
    "    if eval_senteval_transfer:\n",
    "        tasks = ['STSBenchmark', 'SICKRelatedness', 'MR', 'CR', 'SUBJ', 'MPQA', 'SST2', 'TREC', 'MRPC']\n",
    "    model.eval()\n",
    "    results = se.eval(tasks)\n",
    "    \n",
    "    stsb_spearman = results['STSBenchmark']['dev']['spearman'][0]\n",
    "    sickr_spearman = results['SICKRelatedness']['dev']['spearman'][0]\n",
    "\n",
    "    metrics = {\"eval_stsb_spearman\": stsb_spearman, \"eval_sickr_spearman\": sickr_spearman, \"eval_avg_sts\": (stsb_spearman + sickr_spearman) / 2} \n",
    "    if eval_senteval_transfer:\n",
    "        avg_transfer = 0\n",
    "        for task in ['MR', 'CR', 'SUBJ', 'MPQA', 'SST2', 'TREC', 'MRPC']:\n",
    "            avg_transfer += results[task]['devacc']\n",
    "            metrics['eval_{}'.format(task)] = results[task]['devacc']\n",
    "        avg_transfer /= 7\n",
    "        metrics['eval_avg_transfer'] = avg_transfer\n",
    "\n",
    "    logger.info(metrics)\n",
    "    return metrics\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "def print_table(task_names, scores):\n",
    "    tb = PrettyTable()\n",
    "    tb.field_names = task_names\n",
    "    tb.add_row(scores)\n",
    "    print(tb)\n",
    "\n",
    "def test_evaluate(tokenizer, model) -> Dict[str, float]:\n",
    "    # SentEval prepare and batcher\n",
    "    def prepare(params, samples):\n",
    "        return\n",
    "\n",
    "    def batcher(params, batch):\n",
    "        sentences = [' '.join(s) for s in batch]\n",
    "        batch = tokenizer.batch_encode_plus(\n",
    "            sentences,\n",
    "            return_tensors='pt',\n",
    "            padding=True,\n",
    "        )\n",
    "        for k in batch:\n",
    "            batch[k] = batch[k].to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            pooler_output = model(**batch, test=True).view((-1,HID)) \n",
    "        return pooler_output.cpu()\n",
    "\n",
    "    # Set params for SentEval (testmode)\n",
    "    params = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 10}\n",
    "    params['classifier'] = {'nhid': 0, 'optim': 'adam', 'batch_size': 64, 'tenacity': 5, 'epoch_size': 4}\n",
    "\n",
    "    se = senteval.engine.SE(params, batcher, prepare)\n",
    "    tasks = ['STS12', 'STS13', 'STS14', 'STS15', 'STS16', 'STSBenchmark', 'SICKRelatedness']\n",
    "    # tasks += ['MR', 'CR', 'MPQA', 'SUBJ', 'SST2', 'TREC', 'MRPC']\n",
    "\n",
    "    model.eval()\n",
    "    results = {}\n",
    "    for task in tasks:\n",
    "        se = senteval.engine.SE(params, batcher, prepare)\n",
    "        result = se.eval(task)\n",
    "        results[task] = result\n",
    "\n",
    "    print(\"------ test ------\")\n",
    "    task_names = []\n",
    "    scores = []\n",
    "    for task in ['STS12', 'STS13', 'STS14', 'STS15', 'STS16', 'STSBenchmark', 'SICKRelatedness']:\n",
    "        task_names.append(task)\n",
    "        if task in results:\n",
    "            if task in ['STS12', 'STS13', 'STS14', 'STS15', 'STS16']:\n",
    "                scores.append(\"%.2f\" % (results[task]['all']['spearman']['all'] * 100))\n",
    "            else:\n",
    "                scores.append(\"%.2f\" % (results[task]['test']['spearman'].correlation * 100))\n",
    "        else:\n",
    "            scores.append(\"0.00\")\n",
    "    task_names.append(\"Avg.\")\n",
    "    scores.append(\"%.2f\" % (sum([float(score) for score in scores]) / len(scores)))\n",
    "    print_table(task_names, scores)\n",
    "\n",
    "    task_names = []\n",
    "    scores = []\n",
    "    for task in ['MR', 'CR', 'SUBJ', 'MPQA', 'SST2', 'TREC', 'MRPC']:\n",
    "        task_names.append(task)\n",
    "        if task in results:\n",
    "            scores.append(\"%.2f\" % (results[task]['acc']))    \n",
    "        else:\n",
    "            scores.append(\"0.00\")\n",
    "    task_names.append(\"Avg.\")\n",
    "    scores.append(\"%.2f\" % (sum([float(score) for score in scores]) / len(scores)))\n",
    "    print_table(task_names, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3J6vcwXO10i8"
   },
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BIbDB3QaeVYK"
   },
   "outputs": [],
   "source": [
    "def train(model, train_dl, optimizer, lr_scheduler, tokenizer) -> None:\n",
    "    global best\n",
    "    gpus = [0, 1, 2, 3]\n",
    "    torch.cuda.set_device('cuda:{}'.format(gpus[0]))\n",
    "    model = nn.DataParallel(model.to(DEVICE), device_ids=gpus, output_device=gpus[0])\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    early = 0\n",
    "    for epoch in range(EPOCHS):\n",
    "      logger.info(f'epoch: {epoch}')\n",
    "      for batch_idx, batch in enumerate(tqdm(train_dl), start=1):  \n",
    "          model.train()\n",
    "          batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "          optimizer.zero_grad() \n",
    "          with torch.cuda.amp.autocast():\n",
    "            out = model(**batch)\n",
    "            loss = simcse_unsup_loss(out)\n",
    "          scaler.scale(loss).backward()\n",
    "          scaler.step(optimizer)\n",
    "          scaler.update()\n",
    "        \n",
    "                \n",
    "          if batch_idx % SAVE_FREQ == 0: \n",
    "              model.eval()\n",
    "              torch.cuda.empty_cache()\n",
    "              metrics = evaluate(False, tokenizer, model)\n",
    "              corrcoef = metrics[\"eval_stsb_spearman\"]\n",
    "              # corrcoef = metrics[\"eval_avg_sts\"]\n",
    "              if best < corrcoef:\n",
    "                  best = corrcoef\n",
    "                  torch.save(model.state_dict(), SAVE_PATH)\n",
    "                  logger.info(f\"higher corrcoef: {best:.4f} in batch: {batch_idx}, save model\")\n",
    "                  early = 0\n",
    "              else:\n",
    "                early += 1\n",
    "                if early == 4:\n",
    "                  return\n",
    "              torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment on q,v; batch size 512; r=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = ROBERTA\n",
    "BATCH_SIZE = 512\n",
    "RANK = 4\n",
    "TARGET = ['value']\n",
    "PEFT_CONFIG = LoraConfig(inference_mode=False, \n",
    "              r=RANK, \n",
    "              lora_alpha=RANK*2, \n",
    "              lora_dropout=0.05,\n",
    "              # target_modules=[\"q_lin\",\"k_lin\"]\n",
    "              target_modules=TARGET\n",
    "              )\n",
    "SAVE_PATH = f'./saved_model/loracse_sup_{model_path}_r{RANK}_b{BATCH_SIZE}_t{TARGET}.pt'\n",
    "logger.info(f'device: {DEVICE}, pooling: {POOLING}, model path: {model_path}, batch size:{BATCH_SIZE}')\n",
    "# load model\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=data_collator, shuffle=True, num_workers=4, pin_memory=True)\n",
    "assert POOLING in ['cls', 'pooler', 'last-avg', 'first-last-avg']\n",
    "model = SimcseModel(pretrained_model=model_path, pooling=POOLING, peft_config = PEFT_CONFIG).to(DEVICE)\n",
    "optimizer = Lion(model.parameters(), lr=2e-4, weight_decay=1e-2)\n",
    "# train cls with mlp\n",
    "best=0\n",
    "train(model, train_dataloader, optimizer, None, tokenizer)\n",
    "logger.info(f'train is finished, best model is saved at {SAVE_PATH}')\n",
    "# eval\n",
    "model.load_state_dict(torch.load(SAVE_PATH))\n",
    "test_evaluate(tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = ROBERTA\n",
    "BATCH_SIZE = 512\n",
    "RANK = 4\n",
    "TARGET = ['query']\n",
    "PEFT_CONFIG = LoraConfig(inference_mode=False, \n",
    "              r=RANK, \n",
    "              lora_alpha=RANK*2, \n",
    "              lora_dropout=0.05,\n",
    "              # target_modules=[\"q_lin\",\"k_lin\"]\n",
    "              target_modules=TARGET\n",
    "              )\n",
    "SAVE_PATH = f'./saved_model/loracse_sup_{model_path}_r{RANK}_b{BATCH_SIZE}_t{TARGET}.pt'\n",
    "logger.info(f'device: {DEVICE}, pooling: {POOLING}, model path: {model_path}, batch size:{BATCH_SIZE}')\n",
    "# load model\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=data_collator, shuffle=True, num_workers=4, pin_memory=True)\n",
    "assert POOLING in ['cls', 'pooler', 'last-avg', 'first-last-avg']\n",
    "model = SimcseModel(pretrained_model=model_path, pooling=POOLING, peft_config = PEFT_CONFIG).to(DEVICE)\n",
    "optimizer = Lion(model.parameters(), lr=2e-4, weight_decay=1e-2)\n",
    "# train cls with mlp\n",
    "best=0\n",
    "train(model, train_dataloader, optimizer, None, tokenizer)\n",
    "logger.info(f'train is finished, best model is saved at {SAVE_PATH}')\n",
    "# eval\n",
    "model.load_state_dict(torch.load(SAVE_PATH))\n",
    "test_evaluate(tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = ROBERTA\n",
    "BATCH_SIZE = 512\n",
    "RANK = 4\n",
    "TARGET = ['value','query']\n",
    "PEFT_CONFIG = LoraConfig(inference_mode=False, \n",
    "              r=RANK, \n",
    "              lora_alpha=RANK*2, \n",
    "              lora_dropout=0.05,\n",
    "              # target_modules=[\"q_lin\",\"k_lin\"]\n",
    "              target_modules=TARGET\n",
    "              )\n",
    "SAVE_PATH = f'./saved_model/loracse_sup_{model_path}_r{RANK}_b{BATCH_SIZE}_t{TARGET}.pt'\n",
    "logger.info(f'device: {DEVICE}, pooling: {POOLING}, model path: {model_path}, batch size:{BATCH_SIZE}')\n",
    "# load model\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=data_collator, shuffle=True, num_workers=4, pin_memory=True)\n",
    "assert POOLING in ['cls', 'pooler', 'last-avg', 'first-last-avg']\n",
    "model = SimcseModel(pretrained_model=model_path, pooling=POOLING, peft_config = PEFT_CONFIG).to(DEVICE)\n",
    "optimizer = Lion(model.parameters(), lr=2e-4, weight_decay=1e-2)\n",
    "# train cls with mlp\n",
    "best=0\n",
    "train(model, train_dataloader, optimizer, None, tokenizer)\n",
    "logger.info(f'train is finished, best model is saved at {SAVE_PATH}')\n",
    "# eval\n",
    "model.load_state_dict(torch.load(SAVE_PATH))\n",
    "test_evaluate(tokenizer, model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment on different rank 1 2 4 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in [1,2,4,8]:\n",
    "    model_path = ROBERTA\n",
    "    BATCH_SIZE = 512\n",
    "    RANK = r\n",
    "    TARGET = ['value','query']\n",
    "    PEFT_CONFIG = LoraConfig(inference_mode=False, \n",
    "                r=RANK, \n",
    "                lora_alpha=RANK*2, \n",
    "                lora_dropout=0.05,\n",
    "                # target_modules=[\"q_lin\",\"k_lin\"]\n",
    "                target_modules=TARGET\n",
    "                )\n",
    "    SAVE_PATH = f'./saved_model/loracse_sup_{model_path}_r{RANK}_b{BATCH_SIZE}_t{TARGET}.pt'\n",
    "    logger.info(f'device: {DEVICE}, pooling: {POOLING}, model path: {model_path}, batch size:{BATCH_SIZE}')\n",
    "    # load model\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=data_collator, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    assert POOLING in ['cls', 'pooler', 'last-avg', 'first-last-avg']\n",
    "    model = SimcseModel(pretrained_model=model_path, pooling=POOLING, peft_config = PEFT_CONFIG).to(DEVICE)\n",
    "    optimizer = Lion(model.parameters(), lr=2e-4, weight_decay=1e-2)\n",
    "    # train cls with mlp\n",
    "    best=0\n",
    "    train(model, train_dataloader, optimizer, None, tokenizer)\n",
    "    logger.info(f'train is finished, best model is saved at {SAVE_PATH}')\n",
    "    # eval\n",
    "    model.load_state_dict(torch.load(SAVE_PATH))\n",
    "    test_evaluate(tokenizer, model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roberta Large "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roberta Large batch size 452 rank 4 with Lion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-13 16:06:56.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mdevice: cuda, pooling: cls, model path: roberta-large, batch size:452\u001b[0m\n",
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 393216 || all params: 355752960 || trainable%: 0.11053063339234057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-13 16:07:01.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 0\u001b[0m\n",
      " 16%|█▌        | 99/610 [02:27<12:38,  1.49s/it]\u001b[32m2023-04-13 16:10:16.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8263376503356064, 'eval_sickr_spearman': 0.763433896109588, 'eval_avg_sts': 0.7948857732225971}\u001b[0m\n",
      " 16%|█▌        | 99/610 [03:16<16:53,  1.98s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:325] . unexpected pos 489819456 vs 489819344",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:423\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 423\u001b[0m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:650\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    649\u001b[0m num_bytes \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mnbytes()\n\u001b[0;32m--> 650\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:445] . PytorchStreamWriter failed writing file data/200: file write failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# train cls with mlp\u001b[39;00m\n\u001b[1;32m     18\u001b[0m best\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 19\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain is finished, best model is saved at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSAVE_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# eval\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dl, optimizer, lr_scheduler, tokenizer)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best \u001b[38;5;241m<\u001b[39m corrcoef:\n\u001b[1;32m     26\u001b[0m     best \u001b[38;5;241m=\u001b[39m corrcoef\n\u001b[0;32m---> 27\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSAVE_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhigher corrcoef: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in batch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, save model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m     early \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:422\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    419\u001b[0m _check_dill_version(pickle_module)\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 422\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    423\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:290\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:325] . unexpected pos 489819456 vs 489819344"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 450\n",
    "RANK = 4\n",
    "PEFT_CONFIG = LoraConfig(inference_mode=False, \n",
    "              r=RANK, \n",
    "              lora_alpha=RANK*2, \n",
    "              lora_dropout=0.05,\n",
    "              # target_modules=[\"q_lin\",\"k_lin\"]\n",
    "              target_modules=['value','query']\n",
    "              )\n",
    "SAVE_PATH = f'./saved_model/loracse_sup_{model_path}_r{RANK}_b{BATCH_SIZE}.pt'\n",
    "logger.info(f'device: {DEVICE}, pooling: {POOLING}, model path: {model_path}, batch size:{BATCH_SIZE}')\n",
    "# load model\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=data_collator, shuffle=True, num_workers=4, pin_memory=True)\n",
    "assert POOLING in ['cls', 'pooler', 'last-avg', 'first-last-avg']\n",
    "model = SimcseModel(pretrained_model=model_path, pooling=POOLING, peft_config = PEFT_CONFIG).to(DEVICE)\n",
    "optimizer = Lion(model.parameters(), lr=2e-4, weight_decay=1e-2)\n",
    "# train cls with mlp\n",
    "best=0\n",
    "train(model, train_dataloader, optimizer, None, tokenizer)\n",
    "logger.info(f'train is finished, best model is saved at {SAVE_PATH}')\n",
    "# eval\n",
    "model.load_state_dict(torch.load(SAVE_PATH))\n",
    "test_evaluate(tokenizer, model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roberta Large batch size 452 rank 1 with Lion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-13 14:53:52.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mdevice: cuda, pooling: cls, model path: roberta-large, batch size:452\u001b[0m\n",
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 98304 || all params: 355458048 || trainable%: 0.0276555842674295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-13 14:53:58.900\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 0\u001b[0m\n",
      " 16%|█▌        | 99/610 [02:27<12:39,  1.49s/it]\u001b[32m2023-04-13 14:57:14.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.7111494011716875, 'eval_sickr_spearman': 0.697080514499183, 'eval_avg_sts': 0.7041149578354352}\u001b[0m\n",
      "\u001b[32m2023-04-13 14:57:15.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mhigher corrcoef: 0.7111 in batch: 100, save model\u001b[0m\n",
      " 33%|███▎      | 199/610 [05:43<10:10,  1.48s/it]  \u001b[32m2023-04-13 15:00:29.986\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8254029507142806, 'eval_sickr_spearman': 0.7712142140760407, 'eval_avg_sts': 0.7983085823951607}\u001b[0m\n",
      "\u001b[32m2023-04-13 15:00:36.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mhigher corrcoef: 0.8254 in batch: 200, save model\u001b[0m\n",
      " 49%|████▉     | 299/610 [09:04<07:42,  1.49s/it]  \u001b[32m2023-04-13 15:03:50.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8478665676002147, 'eval_sickr_spearman': 0.8221631568954173, 'eval_avg_sts': 0.835014862247816}\u001b[0m\n",
      "\u001b[32m2023-04-13 15:04:02.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mhigher corrcoef: 0.8479 in batch: 300, save model\u001b[0m\n",
      " 65%|██████▌   | 399/610 [12:30<05:13,  1.48s/it]  \u001b[32m2023-04-13 15:07:16.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8637468774635386, 'eval_sickr_spearman': 0.8377156755721795, 'eval_avg_sts': 0.8507312765178591}\u001b[0m\n",
      "\u001b[32m2023-04-13 15:07:27.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mhigher corrcoef: 0.8637 in batch: 400, save model\u001b[0m\n",
      " 82%|████████▏ | 499/610 [15:55<02:44,  1.48s/it]  \u001b[32m2023-04-13 15:10:41.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8708141705844168, 'eval_sickr_spearman': 0.8408082541004753, 'eval_avg_sts': 0.8558112123424461}\u001b[0m\n",
      "\u001b[32m2023-04-13 15:10:47.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mhigher corrcoef: 0.8708 in batch: 500, save model\u001b[0m\n",
      " 98%|█████████▊| 599/610 [19:15<00:16,  1.48s/it]\u001b[32m2023-04-13 15:14:01.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8767228693810554, 'eval_sickr_spearman': 0.8350840995554868, 'eval_avg_sts': 0.8559034844682711}\u001b[0m\n",
      "\u001b[32m2023-04-13 15:14:07.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mhigher corrcoef: 0.8767 in batch: 600, save model\u001b[0m\n",
      "100%|██████████| 610/610 [20:23<00:00,  2.01s/it]\n",
      "\u001b[32m2023-04-13 15:14:22.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 1\u001b[0m\n",
      " 16%|█▌        | 99/610 [02:27<12:39,  1.49s/it]\u001b[32m2023-04-13 15:17:38.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8781333464409515, 'eval_sickr_spearman': 0.8446745656418376, 'eval_avg_sts': 0.8614039560413946}\u001b[0m\n",
      "\u001b[32m2023-04-13 15:17:49.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mhigher corrcoef: 0.8781 in batch: 100, save model\u001b[0m\n",
      " 33%|███▎      | 199/610 [05:54<10:10,  1.49s/it]  \u001b[32m2023-04-13 15:21:03.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8833203322177302, 'eval_sickr_spearman': 0.8429369925162126, 'eval_avg_sts': 0.8631286623669714}\u001b[0m\n",
      "\u001b[32m2023-04-13 15:21:06.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mhigher corrcoef: 0.8833 in batch: 200, save model\u001b[0m\n",
      " 49%|████▉     | 299/610 [09:11<07:42,  1.49s/it]  \u001b[32m2023-04-13 15:24:21.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8827018219004562, 'eval_sickr_spearman': 0.8415957720396545, 'eval_avg_sts': 0.8621487969700554}\u001b[0m\n",
      " 65%|██████▌   | 399/610 [12:25<05:13,  1.49s/it]  \u001b[32m2023-04-13 15:27:35.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8826922268031783, 'eval_sickr_spearman': 0.8365180680889217, 'eval_avg_sts': 0.85960514744605}\u001b[0m\n",
      " 82%|████████▏ | 499/610 [15:40<02:44,  1.49s/it]\u001b[32m2023-04-13 15:30:50.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8840639918784393, 'eval_sickr_spearman': 0.8434571213136859, 'eval_avg_sts': 0.8637605565960627}\u001b[0m\n",
      "\u001b[32m2023-04-13 15:30:53.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mhigher corrcoef: 0.8841 in batch: 500, save model\u001b[0m\n",
      " 98%|█████████▊| 599/610 [18:57<00:16,  1.48s/it]\u001b[32m2023-04-13 15:34:07.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.88210170682375, 'eval_sickr_spearman': 0.8406593576860173, 'eval_avg_sts': 0.8613805322548836}\u001b[0m\n",
      "100%|██████████| 610/610 [19:59<00:00,  1.97s/it]\n",
      "\u001b[32m2023-04-13 15:34:22.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 2\u001b[0m\n",
      " 16%|█▌        | 99/610 [02:27<12:38,  1.49s/it]\u001b[32m2023-04-13 15:37:37.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8835767256326486, 'eval_sickr_spearman': 0.8406827488324176, 'eval_avg_sts': 0.862129737232533}\u001b[0m\n",
      " 33%|███▎      | 199/610 [05:42<10:10,  1.49s/it]  \u001b[32m2023-04-13 15:40:52.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8855831789710517, 'eval_sickr_spearman': 0.839284995749467, 'eval_avg_sts': 0.8624340873602594}\u001b[0m\n",
      "\u001b[32m2023-04-13 15:40:55.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mhigher corrcoef: 0.8856 in batch: 200, save model\u001b[0m\n",
      " 49%|████▉     | 299/610 [09:00<07:42,  1.49s/it]  \u001b[32m2023-04-13 15:44:09.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8827328780767113, 'eval_sickr_spearman': 0.8386075170636825, 'eval_avg_sts': 0.8606701975701969}\u001b[0m\n",
      " 65%|██████▌   | 399/610 [12:14<05:13,  1.49s/it]  \u001b[32m2023-04-13 15:47:24.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8841004011562024, 'eval_sickr_spearman': 0.8417939003330868, 'eval_avg_sts': 0.8629471507446446}\u001b[0m\n",
      " 82%|████████▏ | 499/610 [15:29<02:44,  1.49s/it]\u001b[32m2023-04-13 15:50:38.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8872293971860482, 'eval_sickr_spearman': 0.8399318786236356, 'eval_avg_sts': 0.8635806379048419}\u001b[0m\n",
      "\u001b[32m2023-04-13 15:50:41.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mhigher corrcoef: 0.8872 in batch: 500, save model\u001b[0m\n",
      " 98%|█████████▊| 599/610 [18:46<00:16,  1.48s/it]\u001b[32m2023-04-13 15:53:55.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8848087842067129, 'eval_sickr_spearman': 0.8349937050225803, 'eval_avg_sts': 0.8599012446146466}\u001b[0m\n",
      "100%|██████████| 610/610 [19:48<00:00,  1.95s/it]\n",
      "\u001b[32m2023-04-13 15:54:10.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 3\u001b[0m\n",
      " 16%|█▌        | 99/610 [02:27<12:39,  1.49s/it]\u001b[32m2023-04-13 15:57:26.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8852186093250884, 'eval_sickr_spearman': 0.8356080228099738, 'eval_avg_sts': 0.8604133160675311}\u001b[0m\n",
      " 33%|███▎      | 199/610 [05:42<10:11,  1.49s/it]  \u001b[32m2023-04-13 16:00:40.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8790133096801112, 'eval_sickr_spearman': 0.8364115351059319, 'eval_avg_sts': 0.8577124223930215}\u001b[0m\n",
      " 49%|████▉     | 299/610 [08:57<07:41,  1.49s/it]  \u001b[32m2023-04-13 16:03:55.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8856425178774258, 'eval_sickr_spearman': 0.8384738945394815, 'eval_avg_sts': 0.8620582062084536}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 299/610 [09:44<10:08,  1.96s/it]\n",
      "\u001b[32m2023-04-13 16:03:55.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mtrain is finished, best model is saved at ./saved_model/loracse_sup_roberta-large_r1_b452.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ test ------\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 78.32 | 88.60 | 84.23 | 87.78 | 84.33 |    87.17     |      81.72      | 84.59 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "+------+------+------+------+------+------+------+------+\n",
      "|  MR  |  CR  | SUBJ | MPQA | SST2 | TREC | MRPC | Avg. |\n",
      "+------+------+------+------+------+------+------+------+\n",
      "| 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\n",
      "+------+------+------+------+------+------+------+------+\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 452\n",
    "RANK = 1\n",
    "PEFT_CONFIG = LoraConfig(inference_mode=False, \n",
    "              r=RANK, \n",
    "              lora_alpha=RANK*2, \n",
    "              lora_dropout=0.05,\n",
    "              # target_modules=[\"q_lin\",\"k_lin\"]\n",
    "              target_modules=['value','query']\n",
    "              )\n",
    "SAVE_PATH = f'./saved_model/loracse_sup_{model_path}_r{RANK}_b{BATCH_SIZE}.pt'\n",
    "logger.info(f'device: {DEVICE}, pooling: {POOLING}, model path: {model_path}, batch size:{BATCH_SIZE}')\n",
    "# load model\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=data_collator, shuffle=True, num_workers=4, pin_memory=True)\n",
    "assert POOLING in ['cls', 'pooler', 'last-avg', 'first-last-avg']\n",
    "model = SimcseModel(pretrained_model=model_path, pooling=POOLING, peft_config = PEFT_CONFIG).to(DEVICE)\n",
    "optimizer = Lion(model.parameters(), lr=2e-4, weight_decay=1e-2)\n",
    "# train cls with mlp\n",
    "best=0\n",
    "train(model, train_dataloader, optimizer, None, tokenizer)\n",
    "logger.info(f'train is finished, best model is saved at {SAVE_PATH}')\n",
    "# eval\n",
    "model.load_state_dict(torch.load(SAVE_PATH))\n",
    "test_evaluate(tokenizer, model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "AQJAV8ACvo7A"
   },
   "source": [
    "## Roberta Large batch size 452 rank 2 with Lion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fVy1qr_mvoCE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-13 14:12:21.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mdevice: cuda, pooling: cls, model path: roberta-large, batch size:452\u001b[0m\n",
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 196608 || all params: 355556352 || trainable%: 0.05529587613723745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-13 14:12:28.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 0\u001b[0m\n",
      " 16%|█▌        | 99/610 [02:28<12:37,  1.48s/it]\u001b[32m2023-04-13 14:15:43.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8043958134785762, 'eval_sickr_spearman': 0.7508253477332719, 'eval_avg_sts': 0.7776105806059241}\u001b[0m\n",
      "\u001b[32m2023-04-13 14:15:45.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mhigher corrcoef: 0.8044 in batch: 100, save model\u001b[0m\n",
      " 33%|███▎      | 199/610 [05:44<10:11,  1.49s/it]  \u001b[32m2023-04-13 14:19:00.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8513076678336058, 'eval_sickr_spearman': 0.8200548316977913, 'eval_avg_sts': 0.8356812497656985}\u001b[0m\n",
      "\u001b[32m2023-04-13 14:19:01.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mhigher corrcoef: 0.8513 in batch: 200, save model\u001b[0m\n",
      " 49%|████▉     | 299/610 [09:00<07:42,  1.49s/it]  \u001b[32m2023-04-13 14:22:16.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8638467351835195, 'eval_sickr_spearman': 0.8388416206520918, 'eval_avg_sts': 0.8513441779178057}\u001b[0m\n",
      "\u001b[32m2023-04-13 14:22:29.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mhigher corrcoef: 0.8638 in batch: 300, save model\u001b[0m\n",
      " 65%|██████▌   | 399/610 [12:28<05:13,  1.49s/it]  \u001b[32m2023-04-13 14:25:44.552\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8712194697957819, 'eval_sickr_spearman': 0.8437345489555924, 'eval_avg_sts': 0.8574770093756872}\u001b[0m\n",
      "\u001b[32m2023-04-13 14:25:45.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mhigher corrcoef: 0.8712 in batch: 400, save model\u001b[0m\n",
      " 82%|████████▏ | 499/610 [15:45<02:45,  1.49s/it]\u001b[32m2023-04-13 14:29:01.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8797003724306192, 'eval_sickr_spearman': 0.8411297742935021, 'eval_avg_sts': 0.8604150733620606}\u001b[0m\n",
      "\u001b[32m2023-04-13 14:29:07.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mhigher corrcoef: 0.8797 in batch: 500, save model\u001b[0m\n",
      " 98%|█████████▊| 599/610 [19:06<00:16,  1.49s/it]\u001b[32m2023-04-13 14:32:22.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8805475197039204, 'eval_sickr_spearman': 0.8464688154671599, 'eval_avg_sts': 0.8635081675855402}\u001b[0m\n",
      "\u001b[32m2023-04-13 14:32:29.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mhigher corrcoef: 0.8805 in batch: 600, save model\u001b[0m\n",
      "100%|██████████| 610/610 [20:15<00:00,  1.99s/it]\n",
      "\u001b[32m2023-04-13 14:32:44.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 1\u001b[0m\n",
      " 16%|█▌        | 99/610 [02:27<12:39,  1.49s/it]\u001b[32m2023-04-13 14:35:59.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8838115425202593, 'eval_sickr_spearman': 0.8443212968907604, 'eval_avg_sts': 0.8640664197055099}\u001b[0m\n",
      "\u001b[32m2023-04-13 14:36:01.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mhigher corrcoef: 0.8838 in batch: 100, save model\u001b[0m\n",
      " 33%|███▎      | 199/610 [05:44<10:12,  1.49s/it]  \u001b[32m2023-04-13 14:39:16.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8858237734427105, 'eval_sickr_spearman': 0.8410405805381316, 'eval_avg_sts': 0.863432176990421}\u001b[0m\n",
      "\u001b[32m2023-04-13 14:39:22.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mhigher corrcoef: 0.8858 in batch: 200, save model\u001b[0m\n",
      " 49%|████▉     | 299/610 [09:05<07:42,  1.49s/it]  \u001b[32m2023-04-13 14:42:37.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8832851898447861, 'eval_sickr_spearman': 0.8400698239469658, 'eval_avg_sts': 0.861677506895876}\u001b[0m\n",
      " 65%|██████▌   | 399/610 [12:20<05:13,  1.49s/it]  \u001b[32m2023-04-13 14:45:52.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8852358050664624, 'eval_sickr_spearman': 0.8374544344114576, 'eval_avg_sts': 0.86134511973896}\u001b[0m\n",
      " 82%|████████▏ | 499/610 [15:36<02:45,  1.49s/it]\u001b[32m2023-04-13 14:49:08.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8856854103581469, 'eval_sickr_spearman': 0.8387013218047912, 'eval_avg_sts': 0.862193366081469}\u001b[0m\n",
      " 98%|█████████▊| 599/610 [18:51<00:16,  1.49s/it]\u001b[32m2023-04-13 14:52:23.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8855940544233774, 'eval_sickr_spearman': 0.8341115658135679, 'eval_avg_sts': 0.8598528101184726}\u001b[0m\n",
      " 98%|█████████▊| 599/610 [19:39<00:21,  1.97s/it]\n",
      "\u001b[32m2023-04-13 14:52:23.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mtrain is finished, best model is saved at ./saved_model/loracse_sup_roberta-large_r2_b452.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ test ------\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 78.79 | 87.72 | 83.08 | 87.39 | 84.39 |    86.98     |      82.09      | 84.35 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "+------+------+------+------+------+------+------+------+\n",
      "|  MR  |  CR  | SUBJ | MPQA | SST2 | TREC | MRPC | Avg. |\n",
      "+------+------+------+------+------+------+------+------+\n",
      "| 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\n",
      "+------+------+------+------+------+------+------+------+\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 452\n",
    "SAVE_PATH = f'./saved_model/loracse_sup_{model_path}_r{RANK}_b{BATCH_SIZE}.pt'\n",
    "logger.info(f'device: {DEVICE}, pooling: {POOLING}, model path: {model_path}, batch size:{BATCH_SIZE}')\n",
    "# load model\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=data_collator, shuffle=True, num_workers=4, pin_memory=True)\n",
    "assert POOLING in ['cls', 'pooler', 'last-avg', 'first-last-avg']\n",
    "model = SimcseModel(pretrained_model=model_path, pooling=POOLING, peft_config = PEFT_CONFIG).to(DEVICE)\n",
    "optimizer = Lion(model.parameters(), lr=2e-4, weight_decay=1e-2)\n",
    "# train cls with mlp\n",
    "best=0\n",
    "train(model, train_dataloader, optimizer, None, tokenizer)\n",
    "logger.info(f'train is finished, best model is saved at {SAVE_PATH}')\n",
    "# eval\n",
    "model.load_state_dict(torch.load(SAVE_PATH))\n",
    "test_evaluate(tokenizer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJiebJdC2pMu"
   },
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Hdj870bEvJ0"
   },
   "source": [
    "## Lora-Bert-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RGW7qxvOJMz7",
    "outputId": "db66c41f-5017-4038-df72-912022f643b4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-12 03:01:45.750\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 2>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mdevice: cuda, pooling: cls, model path: bert-base-uncased, batch size:512\u001b[0m\n",
      "\u001b[32m2023-04-12 03:01:45.754\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 0\u001b[0m\n",
      " 23%|██▎       | 124/539 [00:45<02:29,  2.77it/s]\u001b[32m2023-04-12 03:02:48.929\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8554180626237553, 'eval_sickr_spearman': 0.8123737940180112, 'eval_avg_sts': 0.8338959283208833}\u001b[0m\n",
      "\u001b[32m2023-04-12 03:02:50.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8339 in batch: 125, save model\u001b[0m\n",
      " 46%|████▌     | 249/539 [01:49<01:44,  2.77it/s]\u001b[32m2023-04-12 03:03:52.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8569734045737527, 'eval_sickr_spearman': 0.8122038794740944, 'eval_avg_sts': 0.8345886420239236}\u001b[0m\n",
      "\u001b[32m2023-04-12 03:03:53.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8346 in batch: 250, save model\u001b[0m\n",
      " 69%|██████▉   | 374/539 [02:52<00:59,  2.77it/s]\u001b[32m2023-04-12 03:04:55.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8564846604642233, 'eval_sickr_spearman': 0.8109285862068398, 'eval_avg_sts': 0.8337066233355316}\u001b[0m\n",
      " 93%|█████████▎| 499/539 [03:54<00:14,  2.76it/s]\u001b[32m2023-04-12 03:05:57.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8589649486527648, 'eval_sickr_spearman': 0.8129745190036978, 'eval_avg_sts': 0.8359697338282313}\u001b[0m\n",
      "\u001b[32m2023-04-12 03:05:58.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8360 in batch: 500, save model\u001b[0m\n",
      "100%|██████████| 539/539 [04:27<00:00,  2.02it/s]\n",
      "\u001b[32m2023-04-12 03:06:12.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 1\u001b[0m\n",
      " 23%|██▎       | 124/539 [00:45<02:29,  2.77it/s]\u001b[32m2023-04-12 03:07:15.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8572142908609874, 'eval_sickr_spearman': 0.8148942740970777, 'eval_avg_sts': 0.8360542824790326}\u001b[0m\n",
      "\u001b[32m2023-04-12 03:07:16.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8361 in batch: 125, save model\u001b[0m\n",
      " 46%|████▌     | 249/539 [01:48<01:44,  2.77it/s]\u001b[32m2023-04-12 03:08:19.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8566100769208812, 'eval_sickr_spearman': 0.8136738038095351, 'eval_avg_sts': 0.8351419403652082}\u001b[0m\n",
      " 69%|██████▉   | 374/539 [02:51<00:59,  2.76it/s]\u001b[32m2023-04-12 03:09:21.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.859071003886097, 'eval_sickr_spearman': 0.8120392093653933, 'eval_avg_sts': 0.8355551066257452}\u001b[0m\n",
      " 93%|█████████▎| 499/539 [03:53<00:14,  2.77it/s]\u001b[32m2023-04-12 03:10:23.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8576050954011484, 'eval_sickr_spearman': 0.8102028362641099, 'eval_avg_sts': 0.8339039658326292}\u001b[0m\n",
      "100%|██████████| 539/539 [04:24<00:00,  2.04it/s]\n",
      "\u001b[32m2023-04-12 03:10:37.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 10>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mtrain is finished, best model is saved at ./saved_model/loracse_sup_bert-base-uncased_r3_b512_d0.05.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ test ------\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 75.48 | 84.04 | 79.70 | 85.61 | 81.91 |    84.00     |      79.82      | 81.51 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "+------+------+------+------+------+------+------+------+\n",
      "|  MR  |  CR  | SUBJ | MPQA | SST2 | TREC | MRPC | Avg. |\n",
      "+------+------+------+------+------+------+------+------+\n",
      "| 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\n",
      "+------+------+------+------+------+------+------+------+\n"
     ]
    }
   ],
   "source": [
    "# bert batch 512 with mlp, r=2, epoch=4\n",
    "logger.info(f'device: {DEVICE}, pooling: {POOLING}, model path: {model_path}, batch size:{BATCH_SIZE}')\n",
    "# load model\n",
    "assert POOLING in ['cls', 'pooler', 'last-avg', 'first-last-avg']\n",
    "model = SimcseModel(pretrained_model=model_path, pooling=POOLING, peft_config = PEFT_CONFIG).to(DEVICE) \n",
    "optimizer = Lion(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "# train cls with mlp\n",
    "best = 0\n",
    "train(model, train_dataloader, optimizer, None, tokenizer)\n",
    "logger.info(f'train is finished, best model is saved at {SAVE_PATH}')\n",
    "# eval\n",
    "model.load_state_dict(torch.load(SAVE_PATH))\n",
    "test_evaluate(tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jIlFGGEL3P57",
    "outputId": "42e1767b-62ac-4123-b554-3a512dc6d491"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-12 00:59:39.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 3>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mdevice: cuda, pooling: cls, model path: bert-base-uncased, batch size:512\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m2023-04-12 00:59:41.502\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 0\u001b[0m\n",
      "  0%|          | 0/539 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 147456 || all params: 109629696 || trainable%: 0.13450370235451534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 124/539 [00:45<02:29,  2.78it/s]\u001b[32m2023-04-12 01:00:44.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8331040802720957, 'eval_sickr_spearman': 0.7916465485656109, 'eval_avg_sts': 0.8123753144188532}\u001b[0m\n",
      "\u001b[32m2023-04-12 01:00:45.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8331 in batch: 125, save model\u001b[0m\n",
      " 46%|████▌     | 249/539 [01:48<01:44,  2.77it/s]\u001b[32m2023-04-12 01:01:47.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8354498071269327, 'eval_sickr_spearman': 0.7956911035244102, 'eval_avg_sts': 0.8155704553256715}\u001b[0m\n",
      "\u001b[32m2023-04-12 01:01:49.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8354 in batch: 250, save model\u001b[0m\n",
      " 69%|██████▉   | 374/539 [02:52<00:59,  2.78it/s]\u001b[32m2023-04-12 01:02:51.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8423117061253752, 'eval_sickr_spearman': 0.8111542363213962, 'eval_avg_sts': 0.8267329712233857}\u001b[0m\n",
      "\u001b[32m2023-04-12 01:02:52.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8423 in batch: 375, save model\u001b[0m\n",
      " 93%|█████████▎| 499/539 [03:55<00:14,  2.78it/s]\u001b[32m2023-04-12 01:03:54.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8489250060511927, 'eval_sickr_spearman': 0.8132043958551805, 'eval_avg_sts': 0.8310647009531866}\u001b[0m\n",
      "\u001b[32m2023-04-12 01:03:55.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8489 in batch: 500, save model\u001b[0m\n",
      "100%|██████████| 539/539 [04:28<00:00,  2.01it/s]\n",
      "\u001b[32m2023-04-12 01:04:09.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 1\u001b[0m\n",
      " 23%|██▎       | 124/539 [00:45<02:29,  2.77it/s]\u001b[32m2023-04-12 01:05:13.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8501934250737533, 'eval_sickr_spearman': 0.8136549756177714, 'eval_avg_sts': 0.8319242003457623}\u001b[0m\n",
      "\u001b[32m2023-04-12 01:05:14.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8502 in batch: 125, save model\u001b[0m\n",
      " 46%|████▌     | 249/539 [01:49<01:44,  2.78it/s]\u001b[32m2023-04-12 01:06:17.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8528109215373839, 'eval_sickr_spearman': 0.8097603737576621, 'eval_avg_sts': 0.831285647647523}\u001b[0m\n",
      "\u001b[32m2023-04-12 01:06:18.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8528 in batch: 250, save model\u001b[0m\n",
      " 69%|██████▉   | 374/539 [02:52<00:59,  2.78it/s]\u001b[32m2023-04-12 01:07:20.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8538802888215072, 'eval_sickr_spearman': 0.8110277704313096, 'eval_avg_sts': 0.8324540296264085}\u001b[0m\n",
      "\u001b[32m2023-04-12 01:07:21.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8539 in batch: 375, save model\u001b[0m\n",
      " 93%|█████████▎| 499/539 [03:56<00:14,  2.78it/s]\u001b[32m2023-04-12 01:08:24.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8540544473043756, 'eval_sickr_spearman': 0.80887256687868, 'eval_avg_sts': 0.8314635070915278}\u001b[0m\n",
      "\u001b[32m2023-04-12 01:08:25.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8541 in batch: 500, save model\u001b[0m\n",
      "100%|██████████| 539/539 [04:29<00:00,  2.00it/s]\n",
      "\u001b[32m2023-04-12 01:08:39.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 2\u001b[0m\n",
      " 23%|██▎       | 124/539 [00:45<02:29,  2.78it/s]\u001b[32m2023-04-12 01:09:42.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8567239285510865, 'eval_sickr_spearman': 0.8146294306037478, 'eval_avg_sts': 0.8356766795774171}\u001b[0m\n",
      "\u001b[32m2023-04-12 01:09:43.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8567 in batch: 125, save model\u001b[0m\n",
      " 46%|████▌     | 249/539 [01:48<01:44,  2.78it/s]\u001b[32m2023-04-12 01:10:46.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8558752678238223, 'eval_sickr_spearman': 0.8159608527356124, 'eval_avg_sts': 0.8359180602797174}\u001b[0m\n",
      " 69%|██████▉   | 374/539 [02:51<00:59,  2.78it/s]\u001b[32m2023-04-12 01:11:48.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8595017731180061, 'eval_sickr_spearman': 0.8104713781522505, 'eval_avg_sts': 0.8349865756351282}\u001b[0m\n",
      "\u001b[32m2023-04-12 01:11:49.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8595 in batch: 375, save model\u001b[0m\n",
      " 93%|█████████▎| 499/539 [03:55<00:14,  2.78it/s]\u001b[32m2023-04-12 01:12:52.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8561402174233538, 'eval_sickr_spearman': 0.813740326885027, 'eval_avg_sts': 0.8349402721541903}\u001b[0m\n",
      "100%|██████████| 539/539 [04:26<00:00,  2.02it/s]\n",
      "\u001b[32m2023-04-12 01:13:06.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 3\u001b[0m\n",
      " 23%|██▎       | 124/539 [00:45<02:29,  2.78it/s]\u001b[32m2023-04-12 01:14:09.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8582875623178121, 'eval_sickr_spearman': 0.8148111802915897, 'eval_avg_sts': 0.836549371304701}\u001b[0m\n",
      " 46%|████▌     | 249/539 [01:48<01:44,  2.78it/s]\u001b[32m2023-04-12 01:15:12.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8572525046658461, 'eval_sickr_spearman': 0.8061208170461892, 'eval_avg_sts': 0.8316866608560176}\u001b[0m\n",
      " 69%|██████▉   | 374/539 [02:50<00:59,  2.78it/s]\u001b[32m2023-04-12 01:16:14.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8574129086908483, 'eval_sickr_spearman': 0.8115718667484004, 'eval_avg_sts': 0.8344923877196244}\u001b[0m\n",
      " 69%|██████▉   | 374/539 [03:08<01:23,  1.98it/s]\n",
      "\u001b[32m2023-04-12 01:16:14.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 11>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mtrain is finished, best model is saved at ./saved_model/loracse_sup_bert_base_b512_r4_mlp.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ test ------\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 75.13 | 84.25 | 79.76 | 85.83 | 81.40 |    83.83     |      79.79      | 81.43 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "+------+------+------+------+------+------+------+------+\n",
      "|  MR  |  CR  | SUBJ | MPQA | SST2 | TREC | MRPC | Avg. |\n",
      "+------+------+------+------+------+------+------+------+\n",
      "| 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\n",
      "+------+------+------+------+------+------+------+------+\n"
     ]
    }
   ],
   "source": [
    "# bert batch 256 with mlp, r=4，epoch\n",
    "SAVE_PATH = f'./saved_model/loracse_sup_bert_base_b512_r4_mlp.pt'\n",
    "logger.info(f'device: {DEVICE}, pooling: {POOLING}, model path: {model_path}, batch size:{BATCH_SIZE}')\n",
    "# load model\n",
    "assert POOLING in ['cls', 'pooler', 'last-avg', 'first-last-avg']\n",
    "model = SimcseModel(pretrained_model=model_path, pooling=POOLING, peft_config = PEFT_CONFIG).to(DEVICE) \n",
    "optimizer = Lion(model.parameters(), lr=2e-4, weight_decay=1e-2)\n",
    "# train cls with mlp\n",
    "best = 0\n",
    "train(model, train_dataloader, optimizer, None, tokenizer)\n",
    "logger.info(f'train is finished, best model is saved at {SAVE_PATH}')\n",
    "# eval\n",
    "model.load_state_dict(torch.load(SAVE_PATH))\n",
    "test_evaluate(tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yMRM6_VDZVyo",
    "outputId": "415ab959-acca-4a60-dc25-4a20f4b3c97c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-11 22:17:55.334\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 3>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mdevice: cuda, pooling: cls, model path: bert-base-uncased, batch size:512\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m2023-04-11 22:17:57.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 0\u001b[0m\n",
      "  0%|          | 0/539 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 221184 || all params: 109703424 || trainable%: 0.20161996037607724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 124/539 [00:45<02:28,  2.79it/s]\u001b[32m2023-04-11 22:19:00.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8331552601718153, 'eval_sickr_spearman': 0.7949885045725735, 'eval_avg_sts': 0.8140718823721944}\u001b[0m\n",
      "\u001b[32m2023-04-11 22:19:01.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8332 in batch: 125, save model\u001b[0m\n",
      " 46%|████▌     | 249/539 [01:48<01:44,  2.78it/s]\u001b[32m2023-04-11 22:20:03.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8415476796571214, 'eval_sickr_spearman': 0.7991213887269173, 'eval_avg_sts': 0.8203345341920194}\u001b[0m\n",
      "\u001b[32m2023-04-11 22:20:04.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8415 in batch: 250, save model\u001b[0m\n",
      " 69%|██████▉   | 374/539 [02:51<00:59,  2.79it/s]\u001b[32m2023-04-11 22:21:06.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8406697402975088, 'eval_sickr_spearman': 0.8079244329362917, 'eval_avg_sts': 0.8242970866169003}\u001b[0m\n",
      " 93%|█████████▎| 499/539 [03:53<00:14,  2.79it/s]\u001b[32m2023-04-11 22:22:08.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8471928935123386, 'eval_sickr_spearman': 0.8141269292205023, 'eval_avg_sts': 0.8306599113664205}\u001b[0m\n",
      "\u001b[32m2023-04-11 22:22:09.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8472 in batch: 500, save model\u001b[0m\n",
      "100%|██████████| 539/539 [04:26<00:00,  2.02it/s]\n",
      "\u001b[32m2023-04-11 22:22:23.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 1\u001b[0m\n",
      " 23%|██▎       | 124/539 [00:45<02:29,  2.77it/s]\u001b[32m2023-04-11 22:23:26.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8465563834243505, 'eval_sickr_spearman': 0.8088535465625105, 'eval_avg_sts': 0.8277049649934305}\u001b[0m\n",
      " 46%|████▌     | 249/539 [01:47<01:44,  2.79it/s]\u001b[32m2023-04-11 22:24:28.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8522581486506652, 'eval_sickr_spearman': 0.815010413300355, 'eval_avg_sts': 0.8336342809755101}\u001b[0m\n",
      "\u001b[32m2023-04-11 22:24:29.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8523 in batch: 250, save model\u001b[0m\n",
      " 69%|██████▉   | 374/539 [02:50<00:59,  2.79it/s]\u001b[32m2023-04-11 22:25:31.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8577199996495601, 'eval_sickr_spearman': 0.8160172412487006, 'eval_avg_sts': 0.8368686204491304}\u001b[0m\n",
      "\u001b[32m2023-04-11 22:25:32.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8577 in batch: 375, save model\u001b[0m\n",
      " 93%|█████████▎| 499/539 [03:53<00:14,  2.79it/s]\u001b[32m2023-04-11 22:26:34.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8578276918945066, 'eval_sickr_spearman': 0.8102892922466985, 'eval_avg_sts': 0.8340584920706026}\u001b[0m\n",
      "\u001b[32m2023-04-11 22:26:35.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8578 in batch: 500, save model\u001b[0m\n",
      "100%|██████████| 539/539 [04:26<00:00,  2.03it/s]\n",
      "\u001b[32m2023-04-11 22:26:49.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 2\u001b[0m\n",
      " 23%|██▎       | 124/539 [00:45<02:29,  2.78it/s]\u001b[32m2023-04-11 22:27:52.505\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8553063769917427, 'eval_sickr_spearman': 0.8112425174858393, 'eval_avg_sts': 0.833274447238791}\u001b[0m\n",
      " 46%|████▌     | 249/539 [01:47<01:44,  2.78it/s]\u001b[32m2023-04-11 22:28:54.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.856501373998889, 'eval_sickr_spearman': 0.8140875437173231, 'eval_avg_sts': 0.835294458858106}\u001b[0m\n",
      " 69%|██████▉   | 374/539 [02:49<00:59,  2.78it/s]\u001b[32m2023-04-11 22:29:57.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8597587608393832, 'eval_sickr_spearman': 0.8183777777599782, 'eval_avg_sts': 0.8390682692996807}\u001b[0m\n",
      "\u001b[32m2023-04-11 22:29:58.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8598 in batch: 375, save model\u001b[0m\n",
      " 93%|█████████▎| 499/539 [03:53<00:14,  2.78it/s]\u001b[32m2023-04-11 22:31:00.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8579004499517058, 'eval_sickr_spearman': 0.8150171856856577, 'eval_avg_sts': 0.8364588178186818}\u001b[0m\n",
      "100%|██████████| 539/539 [04:24<00:00,  2.04it/s]\n",
      "\u001b[32m2023-04-11 22:31:14.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 3\u001b[0m\n",
      " 23%|██▎       | 124/539 [00:45<02:28,  2.79it/s]\u001b[32m2023-04-11 22:32:16.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8565376241522187, 'eval_sickr_spearman': 0.8137527669402994, 'eval_avg_sts': 0.835145195546259}\u001b[0m\n",
      " 46%|████▌     | 249/539 [01:47<01:44,  2.79it/s]\u001b[32m2023-04-11 22:33:19.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8553874375457601, 'eval_sickr_spearman': 0.8060893566747471, 'eval_avg_sts': 0.8307383971102535}\u001b[0m\n",
      " 69%|██████▉   | 374/539 [02:49<00:59,  2.79it/s]\u001b[32m2023-04-11 22:34:21.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8590071507653022, 'eval_sickr_spearman': 0.8074940742674063, 'eval_avg_sts': 0.8332506125163542}\u001b[0m\n",
      " 69%|██████▉   | 374/539 [03:07<01:22,  2.00it/s]\n",
      "\u001b[32m2023-04-11 22:34:21.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 11>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mtrain is finished, best model is saved at ./saved_model/loracse_sup_bert_base_b512_r6_mlp.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ test ------\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 75.54 | 84.42 | 79.60 | 85.97 | 80.52 |    83.58     |      80.01      | 81.38 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "+------+------+------+------+------+------+------+------+\n",
      "|  MR  |  CR  | SUBJ | MPQA | SST2 | TREC | MRPC | Avg. |\n",
      "+------+------+------+------+------+------+------+------+\n",
      "| 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\n",
      "+------+------+------+------+------+------+------+------+\n"
     ]
    }
   ],
   "source": [
    "# bert batch 512 with mlp, r=6，epoch=4\n",
    "SAVE_PATH = f'./saved_model/loracse_sup_bert_base_b512_r6_mlp.pt'\n",
    "logger.info(f'device: {DEVICE}, pooling: {POOLING}, model path: {model_path}, batch size:{BATCH_SIZE}')\n",
    "# load model\n",
    "assert POOLING in ['cls', 'pooler', 'last-avg', 'first-last-avg']\n",
    "model = SimcseModel(pretrained_model=model_path, pooling=POOLING, peft_config = PEFT_CONFIG).to(DEVICE) \n",
    "optimizer = Lion(model.parameters(), lr=2e-4, weight_decay=1e-2)\n",
    "# train cls with mlp\n",
    "best = 0\n",
    "train(model, train_dataloader, optimizer, None, tokenizer)\n",
    "logger.info(f'train is finished, best model is saved at {SAVE_PATH}')\n",
    "# eval\n",
    "model.load_state_dict(torch.load(SAVE_PATH))\n",
    "test_evaluate(tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "goegBq1eMLrg",
    "outputId": "5e5e7947-c381-4082-afff-b8c4b1a80d09"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-11 21:59:25.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 3>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mdevice: cuda, pooling: cls, model path: bert-base-uncased, batch size:512\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 184320 || all params: 109666560 || trainable%: 0.16807311180363457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-11 21:59:30.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 0\u001b[0m\n",
      " 23%|██▎       | 124/539 [00:46<02:29,  2.77it/s]\u001b[32m2023-04-11 22:00:34.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8307225921250608, 'eval_sickr_spearman': 0.7960561398953397, 'eval_avg_sts': 0.8133893660102003}\u001b[0m\n",
      "\u001b[32m2023-04-11 22:00:35.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8307 in batch: 125, save model\u001b[0m\n",
      " 46%|████▌     | 249/539 [01:49<01:44,  2.77it/s]\u001b[32m2023-04-11 22:01:37.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8399285013518084, 'eval_sickr_spearman': 0.8053199464608101, 'eval_avg_sts': 0.8226242239063093}\u001b[0m\n",
      "\u001b[32m2023-04-11 22:01:39.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8399 in batch: 250, save model\u001b[0m\n",
      " 69%|██████▉   | 374/539 [02:53<00:59,  2.77it/s]\u001b[32m2023-04-11 22:02:41.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.840873076736766, 'eval_sickr_spearman': 0.8098520651303074, 'eval_avg_sts': 0.8253625709335367}\u001b[0m\n",
      "\u001b[32m2023-04-11 22:02:42.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8409 in batch: 375, save model\u001b[0m\n",
      " 93%|█████████▎| 499/539 [03:57<00:14,  2.77it/s]\u001b[32m2023-04-11 22:03:44.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8484495758731332, 'eval_sickr_spearman': 0.8129269201821725, 'eval_avg_sts': 0.8306882480276528}\u001b[0m\n",
      "\u001b[32m2023-04-11 22:03:46.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8484 in batch: 500, save model\u001b[0m\n",
      "100%|██████████| 539/539 [04:29<00:00,  2.00it/s]\n",
      "\u001b[32m2023-04-11 22:04:00.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 1\u001b[0m\n",
      " 23%|██▎       | 124/539 [00:45<02:29,  2.77it/s]\u001b[32m2023-04-11 22:05:03.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8498914060483688, 'eval_sickr_spearman': 0.8178616355439242, 'eval_avg_sts': 0.8338765207961465}\u001b[0m\n",
      "\u001b[32m2023-04-11 22:05:04.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8499 in batch: 125, save model\u001b[0m\n",
      " 46%|████▌     | 249/539 [01:49<01:44,  2.77it/s]\u001b[32m2023-04-11 22:06:06.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8534527669128064, 'eval_sickr_spearman': 0.8226251200290491, 'eval_avg_sts': 0.8380389434709277}\u001b[0m\n",
      "\u001b[32m2023-04-11 22:06:07.553\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8535 in batch: 250, save model\u001b[0m\n",
      " 69%|██████▉   | 374/539 [02:52<00:59,  2.77it/s]\u001b[32m2023-04-11 22:07:09.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8534832003388583, 'eval_sickr_spearman': 0.8121856561936781, 'eval_avg_sts': 0.8328344282662682}\u001b[0m\n",
      "\u001b[32m2023-04-11 22:07:10.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8535 in batch: 375, save model\u001b[0m\n",
      " 93%|█████████▎| 499/539 [03:55<00:14,  2.77it/s]\u001b[32m2023-04-11 22:08:13.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8549423035279401, 'eval_sickr_spearman': 0.8125782143857317, 'eval_avg_sts': 0.8337602589568359}\u001b[0m\n",
      "\u001b[32m2023-04-11 22:08:14.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8549 in batch: 500, save model\u001b[0m\n",
      "100%|██████████| 539/539 [04:28<00:00,  2.01it/s]\n",
      "\u001b[32m2023-04-11 22:08:28.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 2\u001b[0m\n",
      " 23%|██▎       | 124/539 [00:45<02:29,  2.77it/s]\u001b[32m2023-04-11 22:09:30.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8564450813838099, 'eval_sickr_spearman': 0.8176481372980319, 'eval_avg_sts': 0.8370466093409209}\u001b[0m\n",
      "\u001b[32m2023-04-11 22:09:31.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8564 in batch: 125, save model\u001b[0m\n",
      " 46%|████▌     | 249/539 [01:48<01:44,  2.77it/s]\u001b[32m2023-04-11 22:10:34.049\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8572707403158613, 'eval_sickr_spearman': 0.8160985579034354, 'eval_avg_sts': 0.8366846491096483}\u001b[0m\n",
      "\u001b[32m2023-04-11 22:10:35.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8573 in batch: 250, save model\u001b[0m\n",
      " 69%|██████▉   | 374/539 [02:51<00:59,  2.78it/s]\u001b[32m2023-04-11 22:11:37.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8480003300119019, 'eval_sickr_spearman': 0.8202509426849631, 'eval_avg_sts': 0.8341256363484325}\u001b[0m\n",
      " 93%|█████████▎| 499/539 [03:53<00:14,  2.77it/s]\u001b[32m2023-04-11 22:12:39.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8495342634534637, 'eval_sickr_spearman': 0.8226394813283789, 'eval_avg_sts': 0.8360868723909214}\u001b[0m\n",
      "100%|██████████| 539/539 [04:25<00:00,  2.03it/s]\n",
      "\u001b[32m2023-04-11 22:12:53.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 3\u001b[0m\n",
      " 23%|██▎       | 124/539 [00:45<02:29,  2.77it/s]\u001b[32m2023-04-11 22:13:56.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8478698014521879, 'eval_sickr_spearman': 0.8179376687775007, 'eval_avg_sts': 0.8329037351148443}\u001b[0m\n",
      " 46%|████▌     | 249/539 [01:47<01:44,  2.77it/s]\u001b[32m2023-04-11 22:14:58.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8543849963340612, 'eval_sickr_spearman': 0.8171424178309901, 'eval_avg_sts': 0.8357637070825257}\u001b[0m\n",
      " 46%|████▌     | 249/539 [02:04<02:25,  1.99it/s]\n",
      "\u001b[32m2023-04-11 22:14:58.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 11>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mtrain is finished, best model is saved at ./saved_model/loracse_sup_bert_base_b512_r5_mlp.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ test ------\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 74.99 | 83.88 | 79.53 | 86.02 | 81.09 |    83.74     |      79.79      | 81.29 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "+------+------+------+------+------+------+------+------+\n",
      "|  MR  |  CR  | SUBJ | MPQA | SST2 | TREC | MRPC | Avg. |\n",
      "+------+------+------+------+------+------+------+------+\n",
      "| 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\n",
      "+------+------+------+------+------+------+------+------+\n"
     ]
    }
   ],
   "source": [
    "# bert batch 512 with mlp, r=5，epoch=4\n",
    "SAVE_PATH = f'./saved_model/loracse_sup_bert_base_b512_r5_mlp.pt'\n",
    "logger.info(f'device: {DEVICE}, pooling: {POOLING}, model path: {model_path}, batch size:{BATCH_SIZE}')\n",
    "# load model\n",
    "assert POOLING in ['cls', 'pooler', 'last-avg', 'first-last-avg']\n",
    "model = SimcseModel(pretrained_model=model_path, pooling=POOLING, peft_config = PEFT_CONFIG).to(DEVICE) \n",
    "optimizer = Lion(model.parameters(), lr=3e-4, weight_decay=1e-2)\n",
    "# train cls with mlp\n",
    "best = 0\n",
    "train(model, train_dataloader, optimizer, None, tokenizer)\n",
    "logger.info(f'train is finished, best model is saved at {SAVE_PATH}')\n",
    "# eval\n",
    "model.load_state_dict(torch.load(SAVE_PATH))\n",
    "test_evaluate(tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NLw_VRrQExyH",
    "outputId": "934f12af-767d-4c04-b389-259ebbf963d2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-11 21:05:30.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 3>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mdevice: cuda, pooling: cls, model path: bert-base-uncased, batch size:256\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m2023-04-11 21:05:32.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 0\u001b[0m\n",
      "  0%|          | 0/1077 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 147456 || all params: 109629696 || trainable%: 0.13450370235451534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 124/1077 [00:22<02:46,  5.71it/s]\u001b[32m2023-04-11 21:06:12.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8296824501012819, 'eval_sickr_spearman': 0.7932102010729287, 'eval_avg_sts': 0.8114463255871054}\u001b[0m\n",
      "\u001b[32m2023-04-11 21:06:13.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8114 in batch: 125, save model\u001b[0m\n",
      " 23%|██▎       | 249/1077 [01:02<02:25,  5.70it/s]\u001b[32m2023-04-11 21:06:52.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8293059569595671, 'eval_sickr_spearman': 0.7954730903549825, 'eval_avg_sts': 0.8123895236572748}\u001b[0m\n",
      "\u001b[32m2023-04-11 21:06:53.929\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8124 in batch: 250, save model\u001b[0m\n",
      " 35%|███▍      | 374/1077 [01:42<02:03,  5.69it/s]\u001b[32m2023-04-11 21:07:33.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8378609646276197, 'eval_sickr_spearman': 0.8064901281851468, 'eval_avg_sts': 0.8221755464063832}\u001b[0m\n",
      "\u001b[32m2023-04-11 21:07:34.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8222 in batch: 375, save model\u001b[0m\n",
      " 46%|████▋     | 499/1077 [02:23<01:41,  5.69it/s]\u001b[32m2023-04-11 21:08:13.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8400208789257476, 'eval_sickr_spearman': 0.8021482607084456, 'eval_avg_sts': 0.8210845698170965}\u001b[0m\n",
      " 58%|█████▊    | 624/1077 [03:02<01:19,  5.71it/s]\u001b[32m2023-04-11 21:08:52.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8462535380201625, 'eval_sickr_spearman': 0.8061821527627256, 'eval_avg_sts': 0.826217845391444}\u001b[0m\n",
      "\u001b[32m2023-04-11 21:08:53.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8262 in batch: 625, save model\u001b[0m\n",
      " 70%|██████▉   | 749/1077 [03:42<00:57,  5.67it/s]\u001b[32m2023-04-11 21:09:33.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8469677235651406, 'eval_sickr_spearman': 0.8080710718889822, 'eval_avg_sts': 0.8275193977270614}\u001b[0m\n",
      "\u001b[32m2023-04-11 21:09:34.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8275 in batch: 750, save model\u001b[0m\n",
      " 81%|████████  | 874/1077 [04:23<00:35,  5.71it/s]\u001b[32m2023-04-11 21:10:13.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8484987520636104, 'eval_sickr_spearman': 0.810647412139021, 'eval_avg_sts': 0.8295730821013156}\u001b[0m\n",
      "\u001b[32m2023-04-11 21:10:14.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8296 in batch: 875, save model\u001b[0m\n",
      " 93%|█████████▎| 999/1077 [05:03<00:13,  5.72it/s]\u001b[32m2023-04-11 21:10:53.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8542189865635408, 'eval_sickr_spearman': 0.8096379424800964, 'eval_avg_sts': 0.8319284645218186}\u001b[0m\n",
      "\u001b[32m2023-04-11 21:10:54.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8319 in batch: 1000, save model\u001b[0m\n",
      "100%|██████████| 1077/1077 [05:35<00:00,  3.21it/s]\n",
      "\u001b[32m2023-04-11 21:11:08.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 1\u001b[0m\n",
      " 12%|█▏        | 124/1077 [00:22<02:47,  5.70it/s]\u001b[32m2023-04-11 21:11:47.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8537394986890097, 'eval_sickr_spearman': 0.8102111936757602, 'eval_avg_sts': 0.8319753461823849}\u001b[0m\n",
      "\u001b[32m2023-04-11 21:11:49.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8320 in batch: 125, save model\u001b[0m\n",
      " 23%|██▎       | 249/1077 [01:02<02:25,  5.71it/s]\u001b[32m2023-04-11 21:12:28.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8544154785614758, 'eval_sickr_spearman': 0.8089014335706443, 'eval_avg_sts': 0.83165845606606}\u001b[0m\n",
      " 35%|███▍      | 374/1077 [01:41<02:03,  5.69it/s]\u001b[32m2023-04-11 21:13:07.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8518463817275519, 'eval_sickr_spearman': 0.8103823284901841, 'eval_avg_sts': 0.831114355108868}\u001b[0m\n",
      " 46%|████▋     | 499/1077 [02:21<01:41,  5.68it/s]\u001b[32m2023-04-11 21:13:47.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.853936872490349, 'eval_sickr_spearman': 0.814452387963847, 'eval_avg_sts': 0.8341946302270979}\u001b[0m\n",
      "\u001b[32m2023-04-11 21:13:48.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mhigher corrcoef: 0.8342 in batch: 500, save model\u001b[0m\n",
      " 58%|█████▊    | 624/1077 [03:01<01:19,  5.69it/s]\u001b[32m2023-04-11 21:14:27.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8495766310548877, 'eval_sickr_spearman': 0.8105391500363796, 'eval_avg_sts': 0.8300578905456336}\u001b[0m\n",
      " 70%|██████▉   | 749/1077 [03:40<00:57,  5.69it/s]\u001b[32m2023-04-11 21:15:07.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8545217366418286, 'eval_sickr_spearman': 0.8063789361853174, 'eval_avg_sts': 0.830450336413573}\u001b[0m\n",
      " 81%|████████  | 874/1077 [04:20<00:35,  5.68it/s]\u001b[32m2023-04-11 21:15:46.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8512362015922424, 'eval_sickr_spearman': 0.8087364947683058, 'eval_avg_sts': 0.8299863481802741}\u001b[0m\n",
      " 93%|█████████▎| 999/1077 [04:59<00:13,  5.70it/s]\u001b[32m2023-04-11 21:16:25.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.853143458111818, 'eval_sickr_spearman': 0.8075230370215734, 'eval_avg_sts': 0.8303332475666957}\u001b[0m\n",
      " 93%|█████████▎| 999/1077 [05:17<00:24,  3.15it/s]\n",
      "\u001b[32m2023-04-11 21:16:25.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 11>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mtrain is finished, best model is saved at ./saved_model/loracse_sup_bert_base_b256_mlp.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ test ------\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 74.98 | 83.91 | 78.83 | 84.73 | 80.90 |    83.18     |      79.82      | 80.91 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "+------+------+------+------+------+------+------+------+\n",
      "|  MR  |  CR  | SUBJ | MPQA | SST2 | TREC | MRPC | Avg. |\n",
      "+------+------+------+------+------+------+------+------+\n",
      "| 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\n",
      "+------+------+------+------+------+------+------+------+\n"
     ]
    }
   ],
   "source": [
    "# bert batch 256 with mlp, r=4\n",
    "SAVE_PATH = f'./saved_model/loracse_sup_bert_base_b256_mlp.pt'\n",
    "logger.info(f'device: {DEVICE}, pooling: {POOLING}, model path: {model_path}, batch size:{BATCH_SIZE}')\n",
    "# load model\n",
    "assert POOLING in ['cls', 'pooler', 'last-avg', 'first-last-avg']\n",
    "model = SimcseModel(pretrained_model=model_path, pooling=POOLING, peft_config = PEFT_CONFIG).to(DEVICE) \n",
    "optimizer = Lion(model.parameters(), lr=2e-4, weight_decay=1e-2)\n",
    "# train cls with mlp\n",
    "best = 0\n",
    "train(model, train_dataloader, optimizer, None, tokenizer)\n",
    "logger.info(f'train is finished, best model is saved at {SAVE_PATH}')\n",
    "# eval\n",
    "model.load_state_dict(torch.load(SAVE_PATH))\n",
    "test_evaluate(tokenizer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TR8PpGrb0z4R"
   },
   "source": [
    "## Lora-Roberta-base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87nGaONlyvYr"
   },
   "source": [
    "### Roberta-base batch size 512 without mlp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jaltqKkpYA4W",
    "outputId": "b262fb2a-92dc-4f67-d0b2-8011fa19ac06"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-11 04:13:25.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 1>\u001b[0m:\u001b[36m1\u001b[0m - \u001b[1mdevice: cuda, pooling: cls, model path: roberta-base\u001b[0m\n",
      "\u001b[32m2023-04-11 04:13:25.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mepoch: 0\u001b[0m\n",
      " 23%|██▎       | 124/539 [00:45<02:30,  2.76it/s]\u001b[32m2023-04-11 04:14:28.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8565715130938942, 'eval_sickr_spearman': 0.792112162062952, 'eval_avg_sts': 0.824341837578423}\u001b[0m\n",
      "\u001b[32m2023-04-11 04:14:29.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mhigher corrcoef: 0.8566 in batch: 125, save model\u001b[0m\n",
      " 46%|████▌     | 249/539 [01:48<01:44,  2.77it/s]\u001b[32m2023-04-11 04:15:32.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8573582360553504, 'eval_sickr_spearman': 0.7906411135192069, 'eval_avg_sts': 0.8239996747872786}\u001b[0m\n",
      "\u001b[32m2023-04-11 04:15:33.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mhigher corrcoef: 0.8574 in batch: 250, save model\u001b[0m\n",
      " 69%|██████▉   | 374/539 [02:52<00:59,  2.77it/s]\u001b[32m2023-04-11 04:16:35.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.852623770920898, 'eval_sickr_spearman': 0.7902177673911315, 'eval_avg_sts': 0.8214207691560147}\u001b[0m\n",
      " 93%|█████████▎| 499/539 [03:55<00:14,  2.77it/s]\u001b[32m2023-04-11 04:17:38.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8596672305272697, 'eval_sickr_spearman': 0.7995937746095612, 'eval_avg_sts': 0.8296305025684154}\u001b[0m\n",
      "\u001b[32m2023-04-11 04:17:39.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mhigher corrcoef: 0.8597 in batch: 500, save model\u001b[0m\n",
      "100%|██████████| 539/539 [04:27<00:00,  2.01it/s]\n",
      "\u001b[32m2023-04-11 04:17:53.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mepoch: 1\u001b[0m\n",
      " 23%|██▎       | 124/539 [00:45<02:30,  2.76it/s]\u001b[32m2023-04-11 04:18:56.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8561878071851385, 'eval_sickr_spearman': 0.7950157862381902, 'eval_avg_sts': 0.8256017967116644}\u001b[0m\n",
      " 46%|████▌     | 249/539 [01:47<01:44,  2.77it/s]\u001b[32m2023-04-11 04:19:58.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8582929377663521, 'eval_sickr_spearman': 0.79382077243441, 'eval_avg_sts': 0.8260568551003811}\u001b[0m\n",
      " 69%|██████▉   | 374/539 [02:50<00:59,  2.77it/s]\u001b[32m2023-04-11 04:21:01.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8558262705880367, 'eval_sickr_spearman': 0.7894579633974819, 'eval_avg_sts': 0.8226421169927594}\u001b[0m\n",
      " 93%|█████████▎| 499/539 [03:52<00:14,  2.77it/s]\u001b[32m2023-04-11 04:22:03.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.857184347017883, 'eval_sickr_spearman': 0.7922387720463429, 'eval_avg_sts': 0.824711559532113}\u001b[0m\n",
      "100%|██████████| 539/539 [04:23<00:00,  2.04it/s]\n",
      "\u001b[32m2023-04-11 04:22:17.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 9>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mtrain is finished, best model is saved at ./saved_model/simcse_sup_qv_lion__roberta_base.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ test ------\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 74.67 | 83.85 | 78.18 | 84.09 | 81.77 |    84.20     |      79.25      | 80.86 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "|   MR  |   CR  |  SUBJ |  MPQA |  SST2 |  TREC |  MRPC |  Avg. |\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "| 83.37 | 90.30 | 92.35 | 88.99 | 88.85 | 87.60 | 74.26 | 86.53 |\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "#roberta base without mlp\n",
    "logger.info(f'device: {DEVICE}, pooling: {POOLING}, model path: {model_path}')\n",
    "# load model\n",
    "assert POOLING in ['cls', 'pooler', 'last-avg', 'first-last-avg']\n",
    "model = SimcseModel(pretrained_model=model_path, pooling=POOLING, peft_config = PEFT_CONFIG).to(DEVICE) \n",
    "optimizer = Lion(model.parameters(), lr=3e-4, weight_decay=1e-2)\n",
    "# train\n",
    "best=0\n",
    "train(model, train_dataloader, optimizer, None, tokenizer)\n",
    "logger.info(f'train is finished, best model is saved at {SAVE_PATH}')\n",
    "# eval\n",
    "model.load_state_dict(torch.load(SAVE_PATH))\n",
    "test_evaluate(tokenizer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Njqivj34y7z8"
   },
   "source": [
    "### **Roberta-base batch size 512 with mlp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RIQUneZQk_q8",
    "outputId": "ceedc1fc-424c-4630-c103-96021f64e0d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-11 05:00:22.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 1>\u001b[0m:\u001b[36m1\u001b[0m - \u001b[1mdevice: cuda, pooling: cls, model path: roberta-base\u001b[0m\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294912 || all params: 124940544 || trainable%: 0.23604187284473485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-11 05:00:27.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mepoch: 0\u001b[0m\n",
      " 23%|██▎       | 124/539 [00:45<02:27,  2.82it/s]\u001b[32m2023-04-11 05:01:30.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8443887787294697, 'eval_sickr_spearman': 0.8050052466841875, 'eval_avg_sts': 0.8246970127068286}\u001b[0m\n",
      "\u001b[32m2023-04-11 05:01:31.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mhigher corrcoef: 0.8444 in batch: 125, save model\u001b[0m\n",
      " 46%|████▌     | 249/539 [01:48<01:43,  2.81it/s]\u001b[32m2023-04-11 05:02:32.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8603142202964573, 'eval_sickr_spearman': 0.8039910699773217, 'eval_avg_sts': 0.8321526451368895}\u001b[0m\n",
      "\u001b[32m2023-04-11 05:02:33.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mhigher corrcoef: 0.8603 in batch: 250, save model\u001b[0m\n",
      " 69%|██████▉   | 374/539 [02:50<00:58,  2.81it/s]\u001b[32m2023-04-11 05:03:35.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8609480569072876, 'eval_sickr_spearman': 0.8069521393498799, 'eval_avg_sts': 0.8339500981285837}\u001b[0m\n",
      "\u001b[32m2023-04-11 05:03:36.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mhigher corrcoef: 0.8609 in batch: 375, save model\u001b[0m\n",
      " 93%|█████████▎| 499/539 [03:53<00:14,  2.81it/s]\u001b[32m2023-04-11 05:04:37.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8623959014446495, 'eval_sickr_spearman': 0.8037619135923604, 'eval_avg_sts': 0.833078907518505}\u001b[0m\n",
      "\u001b[32m2023-04-11 05:04:38.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mhigher corrcoef: 0.8624 in batch: 500, save model\u001b[0m\n",
      "100%|██████████| 539/539 [04:25<00:00,  2.03it/s]\n",
      "\u001b[32m2023-04-11 05:04:52.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mepoch: 1\u001b[0m\n",
      " 23%|██▎       | 124/539 [00:44<02:27,  2.80it/s]\u001b[32m2023-04-11 05:05:54.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8696700826082914, 'eval_sickr_spearman': 0.8069677014267459, 'eval_avg_sts': 0.8383188920175186}\u001b[0m\n",
      "\u001b[32m2023-04-11 05:05:55.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mhigher corrcoef: 0.8697 in batch: 125, save model\u001b[0m\n",
      " 46%|████▌     | 249/539 [01:47<01:43,  2.80it/s]\u001b[32m2023-04-11 05:06:57.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8694321037967957, 'eval_sickr_spearman': 0.8001129908161071, 'eval_avg_sts': 0.8347725473064513}\u001b[0m\n",
      " 69%|██████▉   | 374/539 [02:48<00:58,  2.80it/s]\u001b[32m2023-04-11 05:07:58.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8726508889305409, 'eval_sickr_spearman': 0.7918282982534528, 'eval_avg_sts': 0.8322395935919968}\u001b[0m\n",
      "\u001b[32m2023-04-11 05:08:00.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mhigher corrcoef: 0.8727 in batch: 375, save model\u001b[0m\n",
      " 93%|█████████▎| 499/539 [03:51<00:14,  2.80it/s]\u001b[32m2023-04-11 05:09:01.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8682165922839628, 'eval_sickr_spearman': 0.7923378121775083, 'eval_avg_sts': 0.8302772022307355}\u001b[0m\n",
      "100%|██████████| 539/539 [04:22<00:00,  2.05it/s]\n",
      "\u001b[32m2023-04-11 05:09:15.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mepoch: 2\u001b[0m\n",
      " 23%|██▎       | 124/539 [00:44<02:28,  2.80it/s]\u001b[32m2023-04-11 05:10:17.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8706897790397193, 'eval_sickr_spearman': 0.8079721278200197, 'eval_avg_sts': 0.8393309534298695}\u001b[0m\n",
      " 46%|████▌     | 249/539 [01:46<01:43,  2.80it/s]\u001b[32m2023-04-11 05:11:18.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8714089948372703, 'eval_sickr_spearman': 0.8087955730230747, 'eval_avg_sts': 0.8401022839301725}\u001b[0m\n",
      " 69%|██████▉   | 374/539 [02:47<00:58,  2.80it/s]\u001b[32m2023-04-11 05:12:20.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.868927240459958, 'eval_sickr_spearman': 0.7980807949142605, 'eval_avg_sts': 0.8335040176871092}\u001b[0m\n",
      " 93%|█████████▎| 499/539 [03:49<00:14,  2.81it/s]\u001b[32m2023-04-11 05:13:21.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8660579687921395, 'eval_sickr_spearman': 0.79994843626258, 'eval_avg_sts': 0.8330032025273597}\u001b[0m\n",
      "100%|██████████| 539/539 [04:19<00:00,  2.07it/s]\n",
      "\u001b[32m2023-04-11 05:13:35.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 9>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mtrain is finished, best model is saved at ./saved_model/simcse_sup_qv_lion_8_roberta_base.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ test ------\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 75.84 | 85.82 | 80.79 | 86.01 | 83.27 |    85.69     |      80.00      | 82.49 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "+------+------+------+------+------+------+------+------+\n",
      "|  MR  |  CR  | SUBJ | MPQA | SST2 | TREC | MRPC | Avg. |\n",
      "+------+------+------+------+------+------+------+------+\n",
      "| 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\n",
      "+------+------+------+------+------+------+------+------+\n"
     ]
    }
   ],
   "source": [
    "# roberta-base 512 with mlp\n",
    "logger.info(f'device: {DEVICE}, pooling: {POOLING}, model path: {model_path}')\n",
    "# load model\n",
    "assert POOLING in ['cls', 'pooler', 'last-avg', 'first-last-avg']\n",
    "model = SimcseModel(pretrained_model=model_path, pooling=POOLING, peft_config = PEFT_CONFIG).to(DEVICE) \n",
    "optimizer = Lion(model.parameters(), lr=3e-4, weight_decay=1e-2)\n",
    "# train\n",
    "best=0\n",
    "train(model, train_dataloader, optimizer, None, tokenizer)\n",
    "logger.info(f'train is finished, best model is saved at {SAVE_PATH}')\n",
    "# eval\n",
    "model.load_state_dict(torch.load(SAVE_PATH))\n",
    "test_evaluate(tokenizer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qY318JL0-2k"
   },
   "source": [
    "## Lora-Roberta-large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Q15jq9czD39"
   },
   "source": [
    "### Roberta-large batch size 364 without mlp with noize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fDLy0ViB5UXU",
    "outputId": "b6e877bf-ee93-4d55-dd1e-04cfad153e07"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-11 02:46:12.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mepoch: 0\u001b[0m\n",
      " 16%|█▌        | 124/788 [01:21<07:14,  1.53it/s]\u001b[32m2023-04-11 02:48:19.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8425739376226038, 'eval_sickr_spearman': 0.8246494868613612, 'eval_avg_sts': 0.8336117122419825}\u001b[0m\n",
      "\u001b[32m2023-04-11 02:48:23.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mhigher corrcoef: 0.8426 in batch: 125, save model\u001b[0m\n",
      " 32%|███▏      | 249/788 [03:32<05:53,  1.52it/s]\u001b[32m2023-04-11 02:50:31.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8543153780889652, 'eval_sickr_spearman': 0.8304111056654715, 'eval_avg_sts': 0.8423632418772183}\u001b[0m\n",
      "\u001b[32m2023-04-11 02:50:34.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mhigher corrcoef: 0.8543 in batch: 250, save model\u001b[0m\n",
      " 47%|████▋     | 374/788 [05:44<04:31,  1.53it/s]\u001b[32m2023-04-11 02:52:42.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8603439462955664, 'eval_sickr_spearman': 0.8257500234886127, 'eval_avg_sts': 0.8430469848920896}\u001b[0m\n",
      "\u001b[32m2023-04-11 02:52:45.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mhigher corrcoef: 0.8603 in batch: 375, save model\u001b[0m\n",
      " 63%|██████▎   | 499/788 [07:55<03:09,  1.52it/s]\u001b[32m2023-04-11 02:54:53.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8673911878012188, 'eval_sickr_spearman': 0.8190120284544685, 'eval_avg_sts': 0.8432016081278437}\u001b[0m\n",
      "\u001b[32m2023-04-11 02:54:57.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mhigher corrcoef: 0.8674 in batch: 500, save model\u001b[0m\n",
      " 79%|███████▉  | 624/788 [10:06<01:47,  1.53it/s]\u001b[32m2023-04-11 02:57:04.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8675221797657184, 'eval_sickr_spearman': 0.8333192927953463, 'eval_avg_sts': 0.8504207362805324}\u001b[0m\n",
      "\u001b[32m2023-04-11 02:57:08.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mhigher corrcoef: 0.8675 in batch: 625, save model\u001b[0m\n",
      " 95%|█████████▌| 749/788 [12:17<00:25,  1.52it/s]\u001b[32m2023-04-11 02:59:15.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.871705035966312, 'eval_sickr_spearman': 0.8162931799264626, 'eval_avg_sts': 0.8439991079463873}\u001b[0m\n",
      "\u001b[32m2023-04-11 02:59:19.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mhigher corrcoef: 0.8717 in batch: 750, save model\u001b[0m\n",
      "100%|██████████| 788/788 [13:31<00:00,  1.03s/it]\n",
      "\u001b[32m2023-04-11 02:59:44.016\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mepoch: 1\u001b[0m\n",
      " 16%|█▌        | 124/788 [01:21<07:15,  1.52it/s]\u001b[32m2023-04-11 03:01:51.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8708858699220261, 'eval_sickr_spearman': 0.8128867181502688, 'eval_avg_sts': 0.8418862940361475}\u001b[0m\n",
      " 32%|███▏      | 249/788 [03:29<05:55,  1.52it/s]\u001b[32m2023-04-11 03:03:59.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.873020818010798, 'eval_sickr_spearman': 0.8104992361910845, 'eval_avg_sts': 0.8417600271009413}\u001b[0m\n",
      "\u001b[32m2023-04-11 03:04:02.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mhigher corrcoef: 0.8730 in batch: 250, save model\u001b[0m\n",
      " 47%|████▋     | 374/788 [05:40<04:31,  1.53it/s]\u001b[32m2023-04-11 03:06:10.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8740067421769865, 'eval_sickr_spearman': 0.8185332544353334, 'eval_avg_sts': 0.8462699983061599}\u001b[0m\n",
      "\u001b[32m2023-04-11 03:06:14.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mhigher corrcoef: 0.8740 in batch: 375, save model\u001b[0m\n",
      " 63%|██████▎   | 499/788 [07:51<03:09,  1.52it/s]\u001b[32m2023-04-11 03:08:22.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.874482212255158, 'eval_sickr_spearman': 0.8080807261403713, 'eval_avg_sts': 0.8412814691977646}\u001b[0m\n",
      "\u001b[32m2023-04-11 03:08:25.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mhigher corrcoef: 0.8745 in batch: 500, save model\u001b[0m\n",
      " 79%|███████▉  | 624/788 [10:03<01:47,  1.53it/s]\u001b[32m2023-04-11 03:10:33.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8721828174339747, 'eval_sickr_spearman': 0.8258193323679878, 'eval_avg_sts': 0.8490010749009813}\u001b[0m\n",
      " 95%|█████████▌| 749/788 [12:10<00:25,  1.52it/s]\u001b[32m2023-04-11 03:12:40.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8741196353804441, 'eval_sickr_spearman': 0.8122942064829283, 'eval_avg_sts': 0.8432069209316861}\u001b[0m\n",
      "100%|██████████| 788/788 [13:21<00:00,  1.02s/it]\n",
      "\u001b[32m2023-04-11 03:13:05.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mepoch: 2\u001b[0m\n",
      " 16%|█▌        | 124/788 [01:21<07:15,  1.53it/s]\u001b[32m2023-04-11 03:15:12.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8684736725320937, 'eval_sickr_spearman': 0.8011525759756336, 'eval_avg_sts': 0.8348131242538637}\u001b[0m\n",
      " 32%|███▏      | 249/788 [03:29<05:54,  1.52it/s]\u001b[32m2023-04-11 03:17:20.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8697711698664851, 'eval_sickr_spearman': 0.8138824509141824, 'eval_avg_sts': 0.8418268103903337}\u001b[0m\n",
      " 47%|████▋     | 374/788 [05:36<04:31,  1.52it/s]\u001b[32m2023-04-11 03:19:28.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8647408166387779, 'eval_sickr_spearman': 0.8057601995365918, 'eval_avg_sts': 0.8352505080876849}\u001b[0m\n",
      " 63%|██████▎   | 499/788 [07:44<03:11,  1.51it/s]\u001b[32m2023-04-11 03:21:35.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8698409635088323, 'eval_sickr_spearman': 0.7929857997670099, 'eval_avg_sts': 0.8314133816379211}\u001b[0m\n",
      " 79%|███████▉  | 624/788 [09:52<01:52,  1.45it/s]\u001b[32m2023-04-11 03:23:43.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8702309993644953, 'eval_sickr_spearman': 0.7955349544136348, 'eval_avg_sts': 0.8328829768890651}\u001b[0m\n",
      " 95%|█████████▌| 749/788 [11:59<00:25,  1.52it/s]\u001b[32m2023-04-11 03:25:51.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8689456052412822, 'eval_sickr_spearman': 0.7942942630323869, 'eval_avg_sts': 0.8316199341368345}\u001b[0m\n",
      "100%|██████████| 788/788 [13:10<00:00,  1.00s/it]\n",
      "\u001b[32m2023-04-11 03:26:15.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 4>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mtrain is finished, best model is saved at ./saved_model/simcse_unsup_qv_roberta_large.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ test ------\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 76.91 | 85.37 | 80.61 | 85.09 | 83.00 |    85.33     |      80.00      | 82.33 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "|   MR  |   CR  |  SUBJ |  MPQA |  SST2 |  TREC |  MRPC |  Avg. |\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "| 84.94 | 90.76 | 93.37 | 89.65 | 90.12 | 81.00 | 76.75 | 86.66 |\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "# roberta-large without mlp\n",
    "best=0\n",
    "train(model, train_dataloader, optimizer, None, tokenizer)\n",
    "logger.info(f'train is finished, best model is saved at {SAVE_PATH}')\n",
    "# eval\n",
    "model.load_state_dict(torch.load(SAVE_PATH))\n",
    "test_evaluate(tokenizer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFQtQ5dLzbRx"
   },
   "source": [
    "### Roberta-large batch size 364 with mlp without noize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MLUsm3hV0YLS",
    "outputId": "bd96897d-d35f-4014-e4fc-a687b7e271f6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-11 15:26:33.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 3>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mdevice: cuda, pooling: cls, model path: roberta-large\u001b[0m\n",
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 786432 || all params: 356146176 || trainable%: 0.22081719613914932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-11 15:26:41.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mepoch: 0\u001b[0m\n",
      " 16%|█▋        | 124/758 [01:20<06:40,  1.58it/s]\u001b[32m2023-04-11 15:28:48.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8461586767449017, 'eval_sickr_spearman': 0.8299913138389023, 'eval_avg_sts': 0.838074995291902}\u001b[0m\n",
      "\u001b[32m2023-04-11 15:28:51.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mhigher corrcoef: 0.8462 in batch: 125, save model\u001b[0m\n",
      " 33%|███▎      | 249/758 [03:28<05:21,  1.58it/s]\u001b[32m2023-04-11 15:30:56.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8696973139437615, 'eval_sickr_spearman': 0.8438459330798274, 'eval_avg_sts': 0.8567716235117944}\u001b[0m\n",
      "\u001b[32m2023-04-11 15:31:00.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mhigher corrcoef: 0.8697 in batch: 250, save model\u001b[0m\n",
      " 49%|████▉     | 374/758 [05:36<04:02,  1.58it/s]\u001b[32m2023-04-11 15:33:05.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8711060907141805, 'eval_sickr_spearman': 0.8390739951208493, 'eval_avg_sts': 0.855090042917515}\u001b[0m\n",
      "\u001b[32m2023-04-11 15:33:08.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mhigher corrcoef: 0.8711 in batch: 375, save model\u001b[0m\n",
      " 66%|██████▌   | 499/758 [07:45<02:43,  1.58it/s]\u001b[32m2023-04-11 15:35:13.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8822522646511098, 'eval_sickr_spearman': 0.8370705218176628, 'eval_avg_sts': 0.8596613932343864}\u001b[0m\n",
      "\u001b[32m2023-04-11 15:35:17.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mhigher corrcoef: 0.8823 in batch: 500, save model\u001b[0m\n",
      " 82%|████████▏ | 624/758 [09:53<01:24,  1.58it/s]\u001b[32m2023-04-11 15:37:22.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.880397545508371, 'eval_sickr_spearman': 0.8329627098982698, 'eval_avg_sts': 0.8566801277033205}\u001b[0m\n",
      " 99%|█████████▉| 749/758 [11:58<00:05,  1.58it/s]\u001b[32m2023-04-11 15:39:27.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8818085251272816, 'eval_sickr_spearman': 0.8325960404698911, 'eval_avg_sts': 0.8572022827985863}\u001b[0m\n",
      "100%|██████████| 758/758 [12:49<00:00,  1.02s/it]\n",
      "\u001b[32m2023-04-11 15:39:31.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mepoch: 1\u001b[0m\n",
      " 16%|█▋        | 124/758 [01:18<06:41,  1.58it/s]\u001b[32m2023-04-11 15:41:36.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8842473008273234, 'eval_sickr_spearman': 0.8290507207794399, 'eval_avg_sts': 0.8566490108033816}\u001b[0m\n",
      "\u001b[32m2023-04-11 15:41:40.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mhigher corrcoef: 0.8842 in batch: 125, save model\u001b[0m\n",
      " 33%|███▎      | 249/758 [03:27<05:21,  1.58it/s]\u001b[32m2023-04-11 15:43:45.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8797586856380178, 'eval_sickr_spearman': 0.8347261237564685, 'eval_avg_sts': 0.8572424046972431}\u001b[0m\n",
      " 49%|████▉     | 374/758 [05:32<04:03,  1.58it/s]\u001b[32m2023-04-11 15:45:50.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8837340033209791, 'eval_sickr_spearman': 0.8357860260719034, 'eval_avg_sts': 0.8597600146964413}\u001b[0m\n",
      " 66%|██████▌   | 499/758 [07:37<02:43,  1.58it/s]\u001b[32m2023-04-11 15:47:55.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8863786154616372, 'eval_sickr_spearman': 0.8253742281509608, 'eval_avg_sts': 0.8558764218062991}\u001b[0m\n",
      "\u001b[32m2023-04-11 15:47:58.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mhigher corrcoef: 0.8864 in batch: 500, save model\u001b[0m\n",
      " 82%|████████▏ | 624/758 [09:45<01:24,  1.58it/s]\u001b[32m2023-04-11 15:50:03.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8808658376456585, 'eval_sickr_spearman': 0.8222905353764312, 'eval_avg_sts': 0.8515781865110448}\u001b[0m\n",
      " 99%|█████████▉| 749/758 [11:50<00:05,  1.58it/s]\u001b[32m2023-04-11 15:52:08.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8780104032958276, 'eval_sickr_spearman': 0.8234056734585198, 'eval_avg_sts': 0.8507080383771737}\u001b[0m\n",
      "100%|██████████| 758/758 [12:41<00:00,  1.00s/it]\n",
      "\u001b[32m2023-04-11 15:52:13.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 11>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mtrain is finished, best model is saved at ./saved_model/simcse_sup_qv_lion_8_roberta-large_v2.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ test ------\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 78.34 | 87.54 | 83.21 | 86.99 | 84.37 |    86.91     |      81.20      | 84.08 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "+------+------+------+------+------+------+------+------+\n",
      "|  MR  |  CR  | SUBJ | MPQA | SST2 | TREC | MRPC | Avg. |\n",
      "+------+------+------+------+------+------+------+------+\n",
      "| 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\n",
      "+------+------+------+------+------+------+------+------+\n"
     ]
    }
   ],
   "source": [
    "# roberta-large with 364 batch size and without noize\n",
    "# roberta-large new\n",
    "logger.info(f'device: {DEVICE}, pooling: {POOLING}, model path: {model_path}')\n",
    "# load model\n",
    "assert POOLING in ['cls', 'pooler', 'last-avg', 'first-last-avg']\n",
    "model = SimcseModel(pretrained_model=model_path, pooling=POOLING, peft_config = PEFT_CONFIG).to(DEVICE) \n",
    "optimizer = Lion(model.parameters(), lr=2e-4, weight_decay=1e-2)\n",
    "# train cls with mlp\n",
    "best=0\n",
    "train(model, train_dataloader, optimizer, None, tokenizer)\n",
    "logger.info(f'train is finished, best model is saved at {SAVE_PATH}')\n",
    "# eval\n",
    "model.load_state_dict(torch.load(SAVE_PATH))\n",
    "test_evaluate(tokenizer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewpZ125yyhWr"
   },
   "source": [
    "### Roberta-large batch size 364 with mlp with noize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178,
     "referenced_widgets": [
      "714ca62536aa4f9ebbda69e656e2587f",
      "968a04b7dde64f84964e0ab5f4a1e594",
      "f8b063a7a48b4d1b9d56781288bdaae9",
      "134f26a0c4fe4af889cab6586bfd0a76",
      "23ed912574d04bf885bf39d1e4d00de9",
      "d0f7d214b00e4333981a049064e3b8e2",
      "e52875960e754f0f9523614b772e3d91",
      "79d79fafd47342f1bc6a213b81c3e6f9"
     ]
    },
    "id": "styFowpc3Zzn",
    "outputId": "da227f96-0c3f-4487-c401-30cfd1a38ebe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-11 14:26:54.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 1>\u001b[0m:\u001b[36m1\u001b[0m - \u001b[1mdevice: cuda, pooling: cls, model path: roberta-large\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714ca62536aa4f9ebbda69e656e2587f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading pytorch_model.bin', max=1425941629.0, style=P…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 786432 || all params: 356146176 || trainable%: 0.22081719613914932\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'device: {DEVICE}, pooling: {POOLING}, model path: {model_path}')\n",
    "# load model\n",
    "assert POOLING in ['cls', 'pooler', 'last-avg', 'first-last-avg']\n",
    "model = SimcseModel(pretrained_model=model_path, pooling=POOLING, peft_config = PEFT_CONFIG).to(DEVICE) \n",
    "optimizer = Lion(model.parameters(), lr=2e-4, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "fMmMOj4CtU3Y",
    "outputId": "118faec5-5e7e-424d-edd5-fa861d6324fc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-11 14:27:31.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mepoch: 0\u001b[0m\n",
      " 16%|█▌        | 124/766 [01:18<06:43,  1.59it/s]\u001b[32m2023-04-11 14:29:43.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8452444625924865, 'eval_sickr_spearman': 0.8103035094527242, 'eval_avg_sts': 0.8277739860226054}\u001b[0m\n",
      "\u001b[32m2023-04-11 14:29:46.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mhigher corrcoef: 0.8452 in batch: 125, save model\u001b[0m\n",
      " 33%|███▎      | 249/766 [03:33<05:25,  1.59it/s]\u001b[32m2023-04-11 14:31:51.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8634561395967669, 'eval_sickr_spearman': 0.8281217032154239, 'eval_avg_sts': 0.8457889214060954}\u001b[0m\n",
      "\u001b[32m2023-04-11 14:31:54.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mhigher corrcoef: 0.8635 in batch: 250, save model\u001b[0m\n",
      " 49%|████▉     | 374/766 [05:41<04:06,  1.59it/s]\u001b[32m2023-04-11 14:33:59.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8696107640621221, 'eval_sickr_spearman': 0.8297612448630137, 'eval_avg_sts': 0.8496860044625679}\u001b[0m\n",
      "\u001b[32m2023-04-11 14:34:02.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mhigher corrcoef: 0.8696 in batch: 375, save model\u001b[0m\n",
      " 65%|██████▌   | 499/766 [07:49<02:47,  1.59it/s]\u001b[32m2023-04-11 14:36:07.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8743875004461924, 'eval_sickr_spearman': 0.8336786614963061, 'eval_avg_sts': 0.8540330809712493}\u001b[0m\n",
      "\u001b[32m2023-04-11 14:36:10.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mhigher corrcoef: 0.8744 in batch: 500, save model\u001b[0m\n",
      " 81%|████████▏ | 624/766 [09:57<01:29,  1.59it/s]\u001b[32m2023-04-11 14:38:15.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8764830898563636, 'eval_sickr_spearman': 0.828566615308045, 'eval_avg_sts': 0.8525248525822042}\u001b[0m\n",
      "\u001b[32m2023-04-11 14:38:18.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mhigher corrcoef: 0.8765 in batch: 625, save model\u001b[0m\n",
      " 98%|█████████▊| 749/766 [12:05<00:10,  1.59it/s]\u001b[32m2023-04-11 14:40:23.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8805964068552183, 'eval_sickr_spearman': 0.8401770293653757, 'eval_avg_sts': 0.8603867181102971}\u001b[0m\n",
      "\u001b[32m2023-04-11 14:40:27.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mhigher corrcoef: 0.8806 in batch: 750, save model\u001b[0m\n",
      "100%|██████████| 766/766 [13:05<00:00,  1.03s/it]\n",
      "\u001b[32m2023-04-11 14:40:36.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mepoch: 1\u001b[0m\n",
      " 16%|█▌        | 124/766 [01:18<06:43,  1.59it/s]\u001b[32m2023-04-11 14:42:41.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8792571247945563, 'eval_sickr_spearman': 0.8329505099985044, 'eval_avg_sts': 0.8561038173965303}\u001b[0m\n",
      " 33%|███▎      | 249/766 [03:22<05:25,  1.59it/s]\u001b[32m2023-04-11 14:44:46.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8786739001938154, 'eval_sickr_spearman': 0.8129906094226794, 'eval_avg_sts': 0.8458322548082474}\u001b[0m\n",
      " 49%|████▉     | 374/766 [05:27<04:06,  1.59it/s]\u001b[32m2023-04-11 14:46:51.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8805545972178985, 'eval_sickr_spearman': 0.8194116472184335, 'eval_avg_sts': 0.849983122218166}\u001b[0m\n",
      " 65%|██████▌   | 499/766 [07:32<02:48,  1.59it/s]\u001b[32m2023-04-11 14:48:55.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8777130276462943, 'eval_sickr_spearman': 0.8290987518808779, 'eval_avg_sts': 0.8534058897635861}\u001b[0m\n",
      " 81%|████████▏ | 624/766 [09:36<01:29,  1.59it/s]\u001b[32m2023-04-11 14:51:00.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8795325972962289, 'eval_sickr_spearman': 0.8221602750293311, 'eval_avg_sts': 0.85084643616278}\u001b[0m\n",
      " 84%|████████▍ | 644/766 [10:35<02:00,  1.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 3&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">58</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">simcse_unsup_loss</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">27</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 3>\u001b[0m:\u001b[94m3\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mtrain\u001b[0m:\u001b[94m58\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92msimcse_unsup_loss\u001b[0m:\u001b[94m27\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train cls with mlp with noize\n",
    "best=0\n",
    "train(model, train_dataloader, optimizer, None, tokenizer)\n",
    "logger.info(f'train is finished, best model is saved at {SAVE_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VO04Rfmry-jH",
    "outputId": "cff94ff9-dc7a-4701-aeac-3f2b50ef371f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ test ------\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 78.65 | 86.89 | 82.79 | 87.01 | 83.89 |    85.87     |      81.39      | 83.78 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "+------+------+------+------+------+------+------+------+\n",
      "|  MR  |  CR  | SUBJ | MPQA | SST2 | TREC | MRPC | Avg. |\n",
      "+------+------+------+------+------+------+------+------+\n",
      "| 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\n",
      "+------+------+------+------+------+------+------+------+\n"
     ]
    }
   ],
   "source": [
    "# eval\n",
    "model.load_state_dict(torch.load(SAVE_PATH))\n",
    "test_evaluate(tokenizer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN-zMP37AY1o"
   },
   "source": [
    "### **Roberta large batch size 375 rank1 use Lion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TfpbQvmeAoLu",
    "outputId": "74223aec-fbbe-44ab-81d9-6ab0bd3e733c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-13 00:39:45.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 3>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mdevice: cuda, pooling: cls, model path: roberta-large, batch size:375\u001b[0m\n",
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 98304 || all params: 355458048 || trainable%: 0.0276555842674295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-13 00:39:53.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 0\u001b[0m\n",
      " 16%|█▋        | 120/735 [01:19<06:38,  1.54it/s]\u001b[32m2023-04-13 00:41:59.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.7708795611471897, 'eval_sickr_spearman': 0.7010389016620021, 'eval_avg_sts': 0.735959231404596}\u001b[0m\n",
      "\u001b[32m2023-04-13 00:42:03.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mhigher corrcoef: 0.7709 in batch: 121, save model\u001b[0m\n",
      " 33%|███▎      | 241/735 [03:26<05:19,  1.55it/s]\u001b[32m2023-04-13 00:44:07.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8382150286390734, 'eval_sickr_spearman': 0.8066187508181749, 'eval_avg_sts': 0.8224168897286241}\u001b[0m\n",
      "\u001b[32m2023-04-13 00:44:10.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mhigher corrcoef: 0.8382 in batch: 242, save model\u001b[0m\n",
      " 49%|████▉     | 362/735 [05:34<04:01,  1.54it/s]\u001b[32m2023-04-13 00:46:14.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8573808230043828, 'eval_sickr_spearman': 0.8347145962921234, 'eval_avg_sts': 0.846047709648253}\u001b[0m\n",
      "\u001b[32m2023-04-13 00:46:18.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mhigher corrcoef: 0.8574 in batch: 363, save model\u001b[0m\n",
      " 66%|██████▌   | 483/735 [07:42<02:43,  1.54it/s]\u001b[32m2023-04-13 00:48:22.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8694498420094982, 'eval_sickr_spearman': 0.8396933081427925, 'eval_avg_sts': 0.8545715750761453}\u001b[0m\n",
      "\u001b[32m2023-04-13 00:48:26.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mhigher corrcoef: 0.8694 in batch: 484, save model\u001b[0m\n",
      " 82%|████████▏ | 604/735 [09:49<01:24,  1.54it/s]\u001b[32m2023-04-13 00:50:30.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8761801438071761, 'eval_sickr_spearman': 0.8361102840377121, 'eval_avg_sts': 0.8561452139224441}\u001b[0m\n",
      "\u001b[32m2023-04-13 00:50:33.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mhigher corrcoef: 0.8762 in batch: 605, save model\u001b[0m\n",
      " 99%|█████████▊| 725/735 [11:57<00:06,  1.55it/s]\u001b[32m2023-04-13 00:52:37.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8781885971505267, 'eval_sickr_spearman': 0.8406301067452414, 'eval_avg_sts': 0.859409351947884}\u001b[0m\n",
      "\u001b[32m2023-04-13 00:52:41.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mhigher corrcoef: 0.8782 in batch: 726, save model\u001b[0m\n",
      "100%|██████████| 735/735 [12:53<00:00,  1.05s/it]\n",
      "\u001b[32m2023-04-13 00:52:47.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 1\u001b[0m\n",
      " 16%|█▋        | 120/735 [01:18<06:39,  1.54it/s]\u001b[32m2023-04-13 00:54:51.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8823291035666532, 'eval_sickr_spearman': 0.8406653135425955, 'eval_avg_sts': 0.8614972085546244}\u001b[0m\n",
      "\u001b[32m2023-04-13 00:54:55.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mhigher corrcoef: 0.8823 in batch: 121, save model\u001b[0m\n",
      " 33%|███▎      | 241/735 [03:25<05:19,  1.54it/s]\u001b[32m2023-04-13 00:56:59.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8839920958175047, 'eval_sickr_spearman': 0.838415296595727, 'eval_avg_sts': 0.8612036962066159}\u001b[0m\n",
      "\u001b[32m2023-04-13 00:57:03.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mhigher corrcoef: 0.8840 in batch: 242, save model\u001b[0m\n",
      " 49%|████▉     | 362/735 [05:33<04:01,  1.54it/s]\u001b[32m2023-04-13 00:59:07.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8849333722678013, 'eval_sickr_spearman': 0.836707214566385, 'eval_avg_sts': 0.8608202934170932}\u001b[0m\n",
      "\u001b[32m2023-04-13 00:59:11.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mhigher corrcoef: 0.8849 in batch: 363, save model\u001b[0m\n",
      " 66%|██████▌   | 483/735 [07:41<02:43,  1.54it/s]\u001b[32m2023-04-13 01:01:15.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8866868770366326, 'eval_sickr_spearman': 0.8403717954817072, 'eval_avg_sts': 0.8635293362591698}\u001b[0m\n",
      "\u001b[32m2023-04-13 01:01:19.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mhigher corrcoef: 0.8867 in batch: 484, save model\u001b[0m\n",
      " 82%|████████▏ | 604/735 [09:49<01:24,  1.54it/s]\u001b[32m2023-04-13 01:03:23.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8866708485558202, 'eval_sickr_spearman': 0.84160095939861, 'eval_avg_sts': 0.8641359039772152}\u001b[0m\n",
      " 99%|█████████▊| 725/735 [11:53<00:06,  1.54it/s]\u001b[32m2023-04-13 01:05:27.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8873599913801595, 'eval_sickr_spearman': 0.8446237967676176, 'eval_avg_sts': 0.8659918940738885}\u001b[0m\n",
      "\u001b[32m2023-04-13 01:05:31.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mhigher corrcoef: 0.8874 in batch: 726, save model\u001b[0m\n",
      "100%|██████████| 735/735 [12:49<00:00,  1.05s/it]\n",
      "\u001b[32m2023-04-13 01:05:36.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 2\u001b[0m\n",
      " 16%|█▋        | 120/735 [01:18<06:39,  1.54it/s]\u001b[32m2023-04-13 01:07:41.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.890557445544052, 'eval_sickr_spearman': 0.847508352595585, 'eval_avg_sts': 0.8690328990698185}\u001b[0m\n",
      "\u001b[32m2023-04-13 01:07:45.352\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mhigher corrcoef: 0.8906 in batch: 121, save model\u001b[0m\n",
      " 33%|███▎      | 241/735 [03:26<05:20,  1.54it/s]\u001b[32m2023-04-13 01:09:49.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8873961604442661, 'eval_sickr_spearman': 0.840998745448779, 'eval_avg_sts': 0.8641974529465225}\u001b[0m\n",
      " 49%|████▉     | 362/735 [05:30<04:01,  1.54it/s]\u001b[32m2023-04-13 01:11:53.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8894891618886688, 'eval_sickr_spearman': 0.8440842634051634, 'eval_avg_sts': 0.8667867126469161}\u001b[0m\n",
      " 66%|██████▌   | 483/735 [07:34<02:43,  1.54it/s]\u001b[32m2023-04-13 01:13:57.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8881606556337741, 'eval_sickr_spearman': 0.8425206108978456, 'eval_avg_sts': 0.8653406332658098}\u001b[0m\n",
      " 82%|████████▏ | 604/735 [09:38<01:24,  1.54it/s]\u001b[32m2023-04-13 01:16:01.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8848512458766055, 'eval_sickr_spearman': 0.8436731652079544, 'eval_avg_sts': 0.86426220554228}\u001b[0m\n",
      " 82%|████████▏ | 604/735 [10:25<02:15,  1.03s/it]\n",
      "\u001b[32m2023-04-13 01:16:02.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 12>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mtrain is finished, best model is saved at ./saved_model/loracse_sup_roberta-large_r1_b375.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ test ------\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 79.06 | 88.57 | 83.62 | 87.80 | 84.50 |    87.26     |      82.00      | 84.69 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "+------+------+------+------+------+------+------+------+\n",
      "|  MR  |  CR  | SUBJ | MPQA | SST2 | TREC | MRPC | Avg. |\n",
      "+------+------+------+------+------+------+------+------+\n",
      "| 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\n",
      "+------+------+------+------+------+------+------+------+\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 375\n",
    "SAVE_PATH = f'./saved_model/loracse_sup_{model_path}_r{RANK}_b{BATCH_SIZE}.pt'\n",
    "logger.info(f'device: {DEVICE}, pooling: {POOLING}, model path: {model_path}, batch size:{BATCH_SIZE}')\n",
    "# load model\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=data_collator, shuffle=True, num_workers=4)\n",
    "assert POOLING in ['cls', 'pooler', 'last-avg', 'first-last-avg']\n",
    "model = SimcseModel(pretrained_model=model_path, pooling=POOLING, peft_config = PEFT_CONFIG).to(DEVICE) \n",
    "optimizer = Lion(model.parameters(), lr=2e-4, weight_decay=1e-2)\n",
    "# train cls with mlp\n",
    "best=0\n",
    "train(model, train_dataloader, optimizer, None, tokenizer)\n",
    "logger.info(f'train is finished, best model is saved at {SAVE_PATH}')\n",
    "# eval\n",
    "model.load_state_dict(torch.load(SAVE_PATH))\n",
    "test_evaluate(tokenizer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzZc6n8I2pmL"
   },
   "source": [
    "### Roberta large batch size 376 rank 1 use Lion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qFtV2mrT2tzK",
    "outputId": "6e25c50b-afd2-483c-9a03-e91b609f60f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-13 05:28:42.297\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 3>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mdevice: cuda, pooling: cls, model path: roberta-large, batch size:376\u001b[0m\n",
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 98304 || all params: 355458048 || trainable%: 0.0276555842674295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-04-13 05:28:49.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 0\u001b[0m\n",
      " 17%|█▋        | 121/733 [01:20<06:36,  1.54it/s]\u001b[32m2023-04-13 05:30:56.538\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.7760251013795039, 'eval_sickr_spearman': 0.7337754290487559, 'eval_avg_sts': 0.7549002652141299}\u001b[0m\n",
      "\u001b[32m2023-04-13 05:31:00.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mhigher corrcoef: 0.7760 in batch: 122, save model\u001b[0m\n",
      " 33%|███▎      | 243/733 [03:28<05:18,  1.54it/s]\u001b[32m2023-04-13 05:33:05.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8362516892058601, 'eval_sickr_spearman': 0.7974616740167233, 'eval_avg_sts': 0.8168566816112917}\u001b[0m\n",
      "\u001b[32m2023-04-13 05:33:08.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mhigher corrcoef: 0.8363 in batch: 244, save model\u001b[0m\n",
      " 50%|████▉     | 365/733 [05:37<03:58,  1.54it/s]\u001b[32m2023-04-13 05:35:13.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8583749660392059, 'eval_sickr_spearman': 0.8271609851244587, 'eval_avg_sts': 0.8427679755818323}\u001b[0m\n",
      "\u001b[32m2023-04-13 05:35:17.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mhigher corrcoef: 0.8584 in batch: 366, save model\u001b[0m\n",
      " 66%|██████▋   | 487/733 [07:46<02:39,  1.54it/s]\u001b[32m2023-04-13 05:37:22.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.871930357956204, 'eval_sickr_spearman': 0.8324071341479351, 'eval_avg_sts': 0.8521687460520695}\u001b[0m\n",
      "\u001b[32m2023-04-13 05:37:25.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mhigher corrcoef: 0.8719 in batch: 488, save model\u001b[0m\n",
      " 83%|████████▎ | 609/733 [09:54<01:20,  1.54it/s]\u001b[32m2023-04-13 05:39:31.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8754298585918875, 'eval_sickr_spearman': 0.8392186167672795, 'eval_avg_sts': 0.8573242376795835}\u001b[0m\n",
      "\u001b[32m2023-04-13 05:39:34.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mhigher corrcoef: 0.8754 in batch: 610, save model\u001b[0m\n",
      "100%|█████████▉| 731/733 [12:03<00:01,  1.54it/s]\u001b[32m2023-04-13 05:41:39.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8762850762639328, 'eval_sickr_spearman': 0.836820039623663, 'eval_avg_sts': 0.8565525579437979}\u001b[0m\n",
      "\u001b[32m2023-04-13 05:41:43.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mhigher corrcoef: 0.8763 in batch: 732, save model\u001b[0m\n",
      "100%|██████████| 733/733 [12:53<00:00,  1.06s/it]\n",
      "\u001b[32m2023-04-13 05:41:43.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mepoch: 1\u001b[0m\n",
      " 17%|█▋        | 121/733 [01:18<06:36,  1.54it/s]\u001b[32m2023-04-13 05:43:49.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8823324718963798, 'eval_sickr_spearman': 0.8452861936875506, 'eval_avg_sts': 0.8638093327919651}\u001b[0m\n",
      "\u001b[32m2023-04-13 05:43:52.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mhigher corrcoef: 0.8823 in batch: 122, save model\u001b[0m\n",
      " 33%|███▎      | 243/733 [03:27<05:18,  1.54it/s]\u001b[32m2023-04-13 05:45:58.283\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8838661900366656, 'eval_sickr_spearman': 0.8381303761019963, 'eval_avg_sts': 0.8609982830693309}\u001b[0m\n",
      "\u001b[32m2023-04-13 05:46:01.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mhigher corrcoef: 0.8839 in batch: 244, save model\u001b[0m\n",
      " 50%|████▉     | 365/733 [05:36<03:59,  1.54it/s]\u001b[32m2023-04-13 05:48:07.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8822484469273613, 'eval_sickr_spearman': 0.8359294949718992, 'eval_avg_sts': 0.8590889709496302}\u001b[0m\n",
      " 66%|██████▋   | 487/733 [07:41<02:39,  1.54it/s]\u001b[32m2023-04-13 05:50:12.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8815071510421194, 'eval_sickr_spearman': 0.8365524583575514, 'eval_avg_sts': 0.8590298046998355}\u001b[0m\n",
      " 83%|████████▎ | 609/733 [09:47<01:20,  1.54it/s]\u001b[32m2023-04-13 05:52:17.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8805273602233794, 'eval_sickr_spearman': 0.8336966731593456, 'eval_avg_sts': 0.8571120166913625}\u001b[0m\n",
      "100%|█████████▉| 731/733 [11:52<00:01,  1.54it/s]\u001b[32m2023-04-13 05:54:22.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m{'eval_stsb_spearman': 0.8818476939817582, 'eval_sickr_spearman': 0.8383957959685433, 'eval_avg_sts': 0.8601217449751508}\u001b[0m\n",
      "100%|█████████▉| 731/733 [12:38<00:02,  1.04s/it]\n",
      "\u001b[32m2023-04-13 05:54:22.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 13>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mtrain is finished, best model is saved at ./saved_model/loracse_sup_roberta-large_r1_b376.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ test ------\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 78.68 | 88.32 | 82.97 | 87.70 | 84.32 |    86.82     |      81.68      | 84.36 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "+------+------+------+------+------+------+------+------+\n",
      "|  MR  |  CR  | SUBJ | MPQA | SST2 | TREC | MRPC | Avg. |\n",
      "+------+------+------+------+------+------+------+------+\n",
      "| 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\n",
      "+------+------+------+------+------+------+------+------+\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 376\n",
    "SAVE_PATH = f'./saved_model/loracse_sup_{model_path}_r{RANK}_b{BATCH_SIZE}.pt'\n",
    "logger.info(f'device: {DEVICE}, pooling: {POOLING}, model path: {model_path}, batch size:{BATCH_SIZE}')\n",
    "# load model\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=data_collator, shuffle=True, num_workers=4, pin_memory=True)\n",
    "assert POOLING in ['cls', 'pooler', 'last-avg', 'first-last-avg']\n",
    "model = SimcseModel(pretrained_model=model_path, pooling=POOLING, peft_config = PEFT_CONFIG).to(DEVICE)\n",
    "# optimizer = Tiger(model.parameters(), lr=2e-4, weight_decay=1e-2)\n",
    "optimizer = Lion(model.parameters(), lr=2e-4, weight_decay=1e-2)\n",
    "# train cls with mlp\n",
    "best=0\n",
    "train(model, train_dataloader, optimizer, None, tokenizer)\n",
    "logger.info(f'train is finished, best model is saved at {SAVE_PATH}')\n",
    "# eval\n",
    "model.load_state_dict(torch.load(SAVE_PATH))\n",
    "test_evaluate(tokenizer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UotOG3Ru0pkl"
   },
   "source": [
    "# Restart The GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  psmisc\n",
      "0 upgraded, 1 newly installed, 0 to remove and 44 not upgraded.\n",
      "Need to get 52.5 kB of archives.\n",
      "After this operation, 266 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 psmisc amd64 23.1-1ubuntu0.1 [52.5 kB]\n",
      "Fetched 52.5 kB in 0s (108 kB/s)  \n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package psmisc.\n",
      "(Reading database ... 13495 files and directories currently installed.)\n",
      "Preparing to unpack .../psmisc_23.1-1ubuntu0.1_amd64.deb ...\n",
      "Unpacking psmisc (23.1-1ubuntu0.1) ...\n",
      "Setting up psmisc (23.1-1ubuntu0.1) ...\n"
     ]
    }
   ],
   "source": [
    "!apt-get install psmisc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIuBu5NEbFaS",
    "outputId": "2627eb8c-106c-4062-9768-ab7e72bace1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     USER        PID ACCESS COMMAND\r\n",
      "/dev/nvidia-modeset: root     kernel mount /dev/nvidia-modeset\r\n",
      "/dev/nvidia-uvm:     root     kernel mount /dev/nvidia-uvm\r\n",
      "/dev/nvidia-uvm-tools:\r\n",
      "                     root     kernel mount /dev/nvidia-uvm-tools\r\n",
      "/dev/nvidia0:        root     kernel mount /dev/nvidia0\r\n",
      "/dev/nvidiactl:      root     kernel mount /dev/nvidiactl\r\n"
     ]
    }
   ],
   "source": [
    "!fuser -v /dev/nvidia*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJ_yN-Efp_Qo"
   },
   "outputs": [],
   "source": [
    "!kill -9 657"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "GSLTP6RlAVCg"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m optimizer\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m model\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "del optimizer\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6QyFA9Ipgvu",
    "outputId": "5f20499f-9c57-4b3f-a4d8-2cf0c802f919"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N--UgynVof6T",
    "outputId": "4af1bb67-2ba4-42d4-ea62-e3118800d5f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 13 13:46:18 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 515.86.01    Driver Version: 515.86.01    CUDA Version: 11.7     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA RTX A6000    On   | 00000000:03:00.0 Off |                  Off |\r\n",
      "| 30%   24C    P2    81W / 300W |   1085MiB / 49140MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "K8K8lwbn2NoW",
    "izHRSyiNyHn8",
    "lAu_bxbcyRMs",
    "B5EXlNRc1sJP",
    "af6MdT8N1iSu",
    "3J6vcwXO10i8",
    "q5HMILHez71N",
    "AQJAV8ACvo7A",
    "gJiebJdC2pMu",
    "_Hdj870bEvJ0",
    "87nGaONlyvYr",
    "_Q15jq9czD39",
    "lFQtQ5dLzbRx",
    "ewpZ125yyhWr",
    "GN-zMP37AY1o"
   ],
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "134f26a0c4fe4af889cab6586bfd0a76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23ed912574d04bf885bf39d1e4d00de9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "714ca62536aa4f9ebbda69e656e2587f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_968a04b7dde64f84964e0ab5f4a1e594",
       "IPY_MODEL_f8b063a7a48b4d1b9d56781288bdaae9"
      ],
      "layout": "IPY_MODEL_134f26a0c4fe4af889cab6586bfd0a76"
     }
    },
    "79d79fafd47342f1bc6a213b81c3e6f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "968a04b7dde64f84964e0ab5f4a1e594": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading pytorch_model.bin: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23ed912574d04bf885bf39d1e4d00de9",
      "max": 1425941629,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d0f7d214b00e4333981a049064e3b8e2",
      "value": 1425941629
     }
    },
    "d0f7d214b00e4333981a049064e3b8e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e52875960e754f0f9523614b772e3d91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8b063a7a48b4d1b9d56781288bdaae9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e52875960e754f0f9523614b772e3d91",
      "placeholder": "​",
      "style": "IPY_MODEL_79d79fafd47342f1bc6a213b81c3e6f9",
      "value": " 1.43G/1.43G [00:04&lt;00:00, 341MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
